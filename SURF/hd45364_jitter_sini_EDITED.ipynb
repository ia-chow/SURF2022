{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ianchow/.local/lib/python3.10/site-packages/radvel/gp.py:32: ImportWarning: celerite not installed. GP kernals using celerite will not work. Try installing celerite using 'pip install celerite'\n",
      "  warnings.warn(\"celerite not installed. GP kernals using celerite will not work. \\\n"
     ]
    }
   ],
   "source": [
    "import radvel\n",
    "import numpy as np\n",
    "import rebound as rb\n",
    "import reboundx\n",
    "import matplotlib.pyplot as plt\n",
    "import celmech as cm\n",
    "import pandas as pd\n",
    "# pd.set_option('display.max_rows', None)\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAY_1_2015 = 57143.5  # barycentric julian date for May 1, 2015 (the date of the HARPS instrument upgrade as per trifonov et al 2020)\n",
    "# 57143.5 is BJD for May 1, 2015\n",
    "# 57173.5 is BJD for May 31, 2015\n",
    "\n",
    "# harps\n",
    "hd_data_harps = pd.read_csv('hd45364_rvs.csv', sep = ';')\n",
    "# giant outlier at position 116 in the data (found manually earlier) which we remove\n",
    "hd_data_harps.drop(116, inplace=True)  # drop the row and keep the df in place\n",
    "# subtract 2.4e6 from all the rows in the data\n",
    "hd_data_harps.BJD -= 2.4e6\n",
    "# rename target to HARPS1 or HARPS2\n",
    "hd_data_harps['target'] = hd_data_harps.apply(lambda row: 'HARPS1' if row.BJD < MAY_1_2015 else 'HARPS2', axis = 1)\n",
    "# hires\n",
    "hd_data_hires = pd.read_csv('hires_rvs.txt', sep = '\\t', index_col=False, header='infer', dtype=np.float64)\n",
    "hd_data_hires['BJD - 2,450,000'] += 50000.  # adding 50000 to have the same units as harps\n",
    "hd_data_hires['target'] = 'HIRES'\n",
    "hd_data_hires.columns = ['BJD', 'RV_mlc_nzp', 'e_RV_mlc_nzp', 'target']\n",
    "# concatenate two data sets one on top of the other\n",
    "hd_data = pd.concat((hd_data_harps, hd_data_hires), axis=0)  # matching BJD, RV_mlc_nzp and e_RV_mlc_nzp columns\n",
    "# reset index\n",
    "hd_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS:\n",
    "\n",
    "STAR_MASS = 920  # 920 jupiter masses\n",
    "G = 2.825e-7  # converting G to jupiter masses, au, and days\n",
    "AUDAY_MS = 1.731e6  # conversion factor for au/day to m/s\n",
    "\n",
    "obs_time_base = np.median(hd_data_harps.BJD)\n",
    "\n",
    "# print(f'nbody_params:{nbody_params}\\n fit_params:{fit_params}')\n",
    "\n",
    "def mass_to_semiamp(planet_mass, star_mass, period, eccentricity, inclination):\n",
    "    \"\"\"\n",
    "    planet mass (jupiter masses) to semi amplitude (in au/day)\n",
    "    \"\"\"\n",
    "    return ((2 * np.pi * G/period) ** (1/3) * (planet_mass * np.sin(inclination) / star_mass ** (2/3)) * (1/np.sqrt(1 - eccentricity ** 2)))\n",
    "\n",
    "\n",
    "def semiamp_to_mass(semiamp, star_mass, period, eccentricity, inclination):\n",
    "    \"\"\"\n",
    "    semi amplitude (in au/day) to planet mass (jupiter masses)\n",
    "    \"\"\"\n",
    "    return (((2 * np.pi * G/period) ** (-1/3)) * (semiamp / np.sin(inclination)) * np.sqrt(1 - eccentricity ** 2) * (star_mass ** (2/3)))\n",
    "\n",
    "\n",
    "def get_sim_from_params(params, integrator, time_base, star_mass = STAR_MASS, auday_ms = AUDAY_MS):\n",
    "    \"\"\"\n",
    "    takes in params array, returns a rebound Simulation object with those parameters\n",
    "    \n",
    "    param params: numpy array of params:\n",
    "    \n",
    "    for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i)\n",
    "    params[5 * num_planets + 4] is jitter for HARPS1\n",
    "    params[5 * num_planets + 5] is jitter for HARPS2\n",
    "    params[5 * num_planets + 6] is jitter for HIRES\n",
    "    \n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    param time_base: base time (to begin integration from) in the simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    num_planets = 2 # 2 planets\n",
    "    \n",
    "    sim = rb.Simulation()\n",
    "    sim.integrator = integrator\n",
    "    sim.t = time_base  # keplerian and n-body models initialized at the same time offset\n",
    "    # print(sim.t)\n",
    "    if integrator == 'whfast':  # if using whfast integrator, set timestep\n",
    "        sim.dt = 1/50 * np.min([params[0], params[5]])  # timestep is 1/20th of the shortest orbital period of any planet\n",
    "        # print(sim.dt)\n",
    "    sim.units = ('AU', 'Mjupiter', 'day')\n",
    "    sim.add(m = star_mass)  # star mass as a constant\n",
    "    \n",
    "    inclination = np.arcsin(params[-4])  # sin(i) is fourth from the back of the array\n",
    "        \n",
    "    for i in range (0, num_planets):\n",
    "        # print(i)\n",
    "        # planet parameters\n",
    "        period = params[5*i]  # in days\n",
    "        semiamp = params[5*i + 1] / auday_ms # divide by auday_ms because semiamp given in m/s\n",
    "        eccentricity = params[5*i + 3] ** 2 + params[5*i + 4] ** 2  # eccentricity from secos, sesin\n",
    "        omega = np.arctan2(params[5*i + 4], params[5*i + 3])  # omega from arctan of sesin, secos  (in that order!)\n",
    "        # get tp by converting from tc\n",
    "        tp = radvel.orbit.timetrans_to_timeperi(tc = params[5*i + 2], per = period, ecc = eccentricity, omega = omega)\n",
    "        \n",
    "        # mass\n",
    "        mass = semiamp_to_mass(semiamp = semiamp, star_mass = star_mass, period = period, eccentricity = eccentricity, inclination = inclination)\n",
    "        \n",
    "        # adding to simulation\n",
    "        sim.add(m = mass, P = period, e = eccentricity, T = tp, omega = omega, inc = inclination)\n",
    "        \n",
    "    sim.move_to_com()  # move to center of mass\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def get_simple_sim(masses, integrator = 'ias15', period_ratio = 3/2, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    gets simple sim (for eccentricity track stuff)\n",
    "    param masses: array of planet masses\n",
    "    param integrator: integrator\n",
    "    param epsilon: amount by which the resonant period ratio should be offset from the equilibrium in the simulation\n",
    "    \"\"\"\n",
    "    sim = rb.Simulation()\n",
    "    sim.integrator = integrator\n",
    "    # central star\n",
    "    sim.add(m = 1)\n",
    "    \n",
    "    sim.add(m = masses[0], P = 1)\n",
    "    sim.add(m = masses[1], P = period_ratio * (1 + epsilon))\n",
    "\n",
    "    sim.move_to_com()\n",
    "    if integrator == 'whfast':\n",
    "        sim.dt = 1/50 * 1  # dy default use 1/50th of the inner planet's orbital period for the timestep if using whfast\n",
    "    return sim\n",
    "\n",
    "\n",
    "def get_rvs(params, instrument, times, integrator, time_base, auday_ms = AUDAY_MS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets RVs from a Numpy array of planet params\n",
    "    \n",
    "    param params:     for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i) (also params[-4])\n",
    "    params[5 * num_planets + 4] is jitter for HARPS1 (also params[-3])\n",
    "    params[5 * num_planets + 5] is jitter for HARPS2 (also params[-2])\n",
    "    params[5 * num_planets + 6] is jitter for HIRES (also params[-1])\n",
    "\n",
    "    param instrument: instrument (HARPS1, HARPS2, or HIRES)\n",
    "    param times: array of times to integrate over\n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sim = get_sim_from_params(params, integrator, time_base = time_base)\n",
    "    \n",
    "    sim_backwards = sim.copy()\n",
    "    sim_backwards.dt *= -1  # set timestep to be negative if integrating backwards\n",
    "\n",
    "    times = pd.Series(times)  # convert to series if not already\n",
    "    \n",
    "    forward_times = times[times - obs_time_base >= 0]\n",
    "    backward_times = times[times - obs_time_base < 0]\n",
    "    forward_indices = forward_times.index\n",
    "    backward_indices = backward_times.index\n",
    "    \n",
    "    # initialize rvs\n",
    "    rv_forward = np.zeros(len(forward_times))\n",
    "    rv_backward = np.zeros(len(backward_times))\n",
    "    \n",
    "    num_planets = 2  # find number of planets in params passed\n",
    "    \n",
    "    # get the rvs (z velocity, assuming 90 deg inclination) from the rebound simulation to compare with the actual simulation\n",
    "    for j, it in enumerate(zip(forward_indices, forward_times)):\n",
    "        i, t = it  # forward index, forward time\n",
    "        sim.integrate(t, exact_finish_time = 1)\n",
    "        # integrate to the specified time, exact_finish_time = 1 for ias15, \n",
    "        # sim.status()\n",
    "        star = sim.particles[0]\n",
    "        # print(instrument[i])\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_forward[j] = (-star.vz * auday_ms) + rv_offset  # use x-velocity of the star as the radial velocity, convert to m/s\n",
    "    \n",
    "    for j, it in enumerate(zip(backward_indices, backward_times)):\n",
    "        i, t = it  # backward index, backward time\n",
    "        sim_backwards.integrate(t, exact_finish_time = 1)\n",
    "        star = sim_backwards.particles[0]\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        # print(instrument[i])\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_backward[j] = (-star.vz * auday_ms) + rv_offset\n",
    "    \n",
    "    return np.concatenate((rv_backward, rv_forward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very original parameters used in Hadden and Payne\n",
    "nbody_params =[ 2.27798546e+02,  7.25405874e+00,  5.39392010e+04,  1.71866112e-01, 1.17923823e-01,  \n",
    "               3.43881599e+02,  1.87692753e+01,  5.40138425e+04, 1.68408461e-01,  5.05903191e-02, \n",
    "               -3.28526403e-03, 0., 0., \n",
    "               1, \n",
    "               1.84, 0., 0.]  # inserted 0 for harps2 and hires for both rv offset and jitter\n",
    "\n",
    "# #Least squares fit: \n",
    "# fit_params = [ 2.28512793e+02, 7.27736501e+00, 5.39371914e+04, -4.66868256e-02, \n",
    "#                -1.78080009e-01, 3.43378038e+02, 1.78603341e+01, 5.40186750e+04, \n",
    "#                9.72945632e-02,  1.32194117e-01, -5.29072002e-01, 0., 0., 1, 2.428]#-7.68527759e-03] \n",
    "\n",
    "# Neg log likelihood jitter fit:\n",
    "\n",
    "fit_params = [2.27859008e+02, 7.20396587e+00,  5.39386707e+04, -7.17270858e-03, -2.13670237e-01,\n",
    "              3.44028221e+02, 1.82216479e+01,  5.47055869e+04, 1.14530821e-01,  3.81765820e-02,\n",
    "              -1.38087163e-01, -2.89290650e+00, 1.70788055e+00, \n",
    "              1.00000000e+00,\n",
    "              2.15025156e+00, 1.48605174e+00, 4.42809302e+00] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a negative log-likelihood function to minimize for the least-squares fit with jitter, using equation (1) from this paper https://iopscience.iop.org/article/10.1088/0004-637X/794/1/51/pdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_log_likelihood(params, data = hd_data):\n",
    "    \"\"\"\n",
    "    Gets the negative log-likelihood (including a jitter term!) for use with scipy.optimize.minimze\n",
    "    \n",
    "    Iplements the log likelihood using the same method above\n",
    "    \n",
    "    \"\"\"\n",
    "    obs_y = data.RV_mlc_nzp  # observed RVs\n",
    "    \n",
    "    # inclination not handled sparately\n",
    "    # inclination = np.arcsin(params[-4])  # inclination is np.arcsin of the second to last parameter\n",
    "    \n",
    "    synth_y = get_rvs(params, data.target, data.BJD, 'ias15', time_base = obs_time_base)  # RVs from the rebound simulation\n",
    "    obs_yerr = data.e_RV_mlc_nzp  # y errors\n",
    "\n",
    "    conditions = [data.target == 'HARPS1', data.target == 'HARPS2', data.target == 'HIRES']  # conditions are harps1, harps2 or hires\n",
    "    jitters = params[-3:]  # jitters for HARPS1, HARPS2 and HIRES, in that order\n",
    "    \n",
    "    # get the jitter values for the corresponding data points\n",
    "    jitter = np.select(conditions, jitters, default=np.nan)\n",
    "\n",
    "    # compute the log-likelihood\n",
    "    log_likelihood = -1/2 * np.sum(((obs_y - synth_y) ** 2)/(obs_yerr ** 2 + jitter ** 2) \n",
    "                                   + np.log(np.sqrt(2 * np.pi * (obs_yerr ** 2 + jitter ** 2))))\n",
    "    \n",
    "    # log_likelihood = -1/2 * np.sum(np.log(variance) + ((obs_y - synth_y) ** 2/variance))\n",
    "    \n",
    "    return -log_likelihood  # negative since we are trying to minimize the negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 145.836993516676$"
      ],
      "text/plain": [
       "145.83699351667633"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test on fit_params\n",
    "neg_log_likelihood(fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now find the fit by maximizing the log likelihood (minimizing the negative log likelihood), with appropriate bounds (bounds of [0, 1] for sin(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bounds of (0, 1) for sin(i), everything else can vary however\n",
    "bounds = ((None, None), (None, None), (None, None), (None, None), (None, None), \n",
    "          (None, None), (None, None), (None, None), (None, None), (None, None), \n",
    "          (None, None), (None, None), (None, None),\n",
    "          (0, 1), \n",
    "          (None, None), (None, None), (None, None))\n",
    "\n",
    "best_fit_jitter = optimize.minimize(neg_log_likelihood, x0=np.array(fit_params), method='Nelder-Mead', \n",
    "                                    bounds=bounds, options={'maxiter': np.inf, 'maxfev': np.inf})  # optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( 1442.34396742473, \\  145.836993516604\\right)$"
      ],
      "text/plain": [
       "(1442.3439674247297, 145.83699351660437)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_log_likelihood(nbody_params), neg_log_likelihood(best_fit_jitter.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original guess:\n",
      "[ 2.27859008e+02  7.20396587e+00  5.39386707e+04 -7.17270858e-03\n",
      " -2.13670237e-01  3.44028221e+02  1.82216479e+01  5.47055869e+04\n",
      "  1.14530821e-01  3.81765820e-02 -1.38087163e-01 -2.89290650e+00\n",
      "  1.70788055e+00  1.00000000e+00  2.15025156e+00  1.48605174e+00\n",
      "  4.42809302e+00]\n",
      "\n",
      "optimization with jitter:\n",
      "[ 2.27859014e+02  7.20396610e+00  5.39386707e+04 -7.17559020e-03\n",
      " -2.13669346e-01  3.44028217e+02  1.82216589e+01  5.47055869e+04\n",
      "  1.14531498e-01  3.81775332e-02 -1.38093056e-01 -2.89290989e+00\n",
      "  1.70793414e+00  1.00000000e+00  2.15024775e+00  1.48604155e+00\n",
      "  4.42811849e+00]\n",
      "\n",
      "        message: Optimization terminated successfully.\n",
      "       success: True\n",
      "        status: 0\n",
      "           fun: 145.83699351660437\n",
      "             x: [ 2.279e+02  7.204e+00 ...  1.486e+00  4.428e+00]\n",
      "           nit: 235\n",
      "          nfev: 485\n",
      " final_simplex: (array([[ 2.279e+02,  7.204e+00, ...,  1.486e+00,\n",
      "                         4.428e+00],\n",
      "                       [ 2.279e+02,  7.204e+00, ...,  1.486e+00,\n",
      "                         4.428e+00],\n",
      "                       ...,\n",
      "                       [ 2.279e+02,  7.204e+00, ...,  1.486e+00,\n",
      "                         4.428e+00],\n",
      "                       [ 2.279e+02,  7.204e+00, ...,  1.486e+00,\n",
      "                         4.428e+00]]), array([ 1.458e+02,  1.458e+02, ...,  1.458e+02,  1.458e+02]))\n"
     ]
    }
   ],
   "source": [
    "print(f'original guess:\\n{np.array(fit_params)}\\n\\noptimization with jitter:\\n{best_fit_jitter.x}\\n\\n', best_fit_jitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NBODY_VS_PREV_FINAL equivalent but using the jitter fit parameters instead of the original fit parameters without any jitter**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 8))\n",
    "# plt.rc('font', size = 18)\n",
    "# # pltot the observed RVs\n",
    "# plt.errorbar(hd_data.BJD, hd_data.RV_mlc_nzp, yerr = hd_data.e_RV_mlc_nzp, fmt= 'o', label = 'Observed RVs')\n",
    "# times = np.linspace(np.min(hd_data.BJD), np.max(hd_data.BJD), int(1e4))  # time array\n",
    "# # pltot the REBOUND n-body reuslt for original parameters and least-squares fit\n",
    "# plt.plot(times, get_rvs(nbody_params, times, 'ias15', obs_time_base), label = 'Previous fit', color='darkgreen')#, color='black')\n",
    "# # plt.plot(times, get_rvs(fit_params, np.pi/2, times, 'ias15', obs_time_base), label = 'New fit (no jitter)', color='orange')#, color='orange')\n",
    "# plt.plot(times, get_rvs(best_fit_jitter.x, times, 'ias15', obs_time_base), label = 'New fit (jitter)', color='red')\n",
    "# # pltot the Keplterian result\n",
    "# # plt.pltot(times, post.model(times), label = 'Keplterian')\n",
    "# plt.axvline(x = 54650, color='black', label='New data')\n",
    "# plt.xlabel('BJD - 2.4e6'), plt.ylabel('Radial Velocity (m/s)')\n",
    "# # plt.ylim(bottom = -30)\n",
    "# # plt.title('N-body least-squares fit vs. previous fit')\n",
    "# plt.legend(loc = 'lower left')\n",
    "# plt.savefig('nbody_vs_prev_final_jitter.png', pad_inches=0)# fmt = 'png', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare to the observed RV data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 8))\n",
    "# plt.rc('font', size = 18)\n",
    "# # plot observed RVs\n",
    "# plt.errorbar(hd_data.BJD, hd_data.RV_mlc_nzp, yerr = hd_data.e_RV_mlc_nzp, fmt= 'o', label = 'Observed RVs')\n",
    "# # plot the RV curve for original least-squares optimization (without jitter) and the nonlinear optimization (with jitter)\n",
    "# times = np.linspace(np.min(hd_data.BJD), np.max(hd_data.BJD), int(1e4))  # time array\n",
    "# # original least squares optimization (no jitter)\n",
    "# plt.plot(times, get_rvs(fit_params, times, 'ias15', obs_time_base), label = 'Least-squares (no jitter)', color='blue')\n",
    "# # nonlinear optimization (jitter)\n",
    "# plt.plot(times, get_rvs(best_fit_jitter.x, times, 'ias15', obs_time_base), label = 'Nonlinear (jitter)', color='orange')\n",
    "# plt.axvline(x = 54650, c='k', label = 'New data')\n",
    "# plt.xlabel('BJD - 2.4e6'), plt.ylabel('Radial Velocity (m/s)')\n",
    "# plt.legend(loc = 'lower left')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jitter:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the best-fit jitter values simultaneously by a single factor:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now changing jitter, holding the planet parameters constant and plotting likelihood as a function of jitter for the original solution without jitter as a parameter and the solution with jitter as a parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_sfs = np.linspace(0., 2.5, int(1e3))  # try 1000 from 0 to 2.5\n",
    "# get the best-fit jitter values\n",
    "fit_param_jitters = np.array(fit_params[-3:])\n",
    "# scale all of them simultaneously by a single factor from 0 to 2.5\n",
    "# without jitter as a parameter set of params\n",
    "# no_jitter_neg_log_likelihoods = [neg_log_likelihood(np.append(fit_params[:-3], jitter_sf * jitters)) for jitter_sf in jitter_sfs]\n",
    "# jitter as a parameter set of params\n",
    "# scale all of the best fit jitter values simultaneously by jitter_sf scale factor\n",
    "jitter_neg_log_likelihoods = [neg_log_likelihood(np.append(best_fit_jitter.x[:-3], jitter_sf * fit_param_jitters)) for jitter_sf in jitter_sfs]  # compute negative log likelihood for each"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 8))\n",
    "# no jitter fit\n",
    "# plt.scatter(jitters, no_jitter_neg_log_likelihoods, label = 'no jitter fit')\n",
    "# jitter fit\n",
    "plt.scatter(jitter_sfs, jitter_neg_log_likelihoods)#, label = 'jitter fit')\n",
    "plt.xlabel('jitter scale factor for best-fit value'), plt.ylabel('negative log likelihood')\n",
    "plt.axvline(1., color = 'k')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitter that produces the minimum negative log likelihood for different values\n",
    "# jitters[np.argmin(no_jitter_neg_log_likelihoods)], \n",
    "jitter_sfs[np.argmin(jitter_neg_log_likelihoods)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # minimum negative log likelihood\n",
    "# neg_log_likelihood(params=np.append(best_fit_jitter.x[:-3], jitter_sfs[np.argmin(jitter_neg_log_likelihoods)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try optimizing again with the jitter producing the minimum negative log likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_fit_jitter2 = optimize.minimize(neg_log_likelihood, x0=np.append(best_fit_jitter.x[:-1], jitters[np.argmin(jitter_neg_log_likelihoods)]), method='Nelder-Mead', bounds=bounds, options={'maxiter': int(1e5), 'maxfev': int(1e5)})  # optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(14, 8))\n",
    "# plt.rc('font', size = 18)\n",
    "# # plot observed RVs\n",
    "# plt.errorbar(hd_data.BJD, hd_data.RV_mlc_nzp, yerr = hd_data.e_RV_mlc_nzp, fmt= 'o', label = 'Observed RVs')\n",
    "# # plot the RV curve for original least-squares optimization (without jitter) and the nonlinear optimization (with jitter)\n",
    "# times = np.linspace(np.min(hd_data.BJD), np.max(hd_data.BJD), int(1e4))  # time array\n",
    "# # original least squares optimization (no jitter)\n",
    "# # plt.plot(times, get_rvs(fit_params, np.pi/2, times, 'ias15', obs_time_base), label = 'Least-squares (no jitter)', color='blue')\n",
    "# # nonlinear optimization (jitter)\n",
    "# # plt.plot(times, get_rvs(best_fit_jitter.x, np.pi/2, times, 'ias15', obs_time_base), label = 'Nonlinear fit from LS solution (jitter)', color='orange')\n",
    "# # nonlinear optimization (jitter) with the jitter producing the minimum negative log likelihood manually added\n",
    "# plt.plot(times, get_rvs(best_fit_jitter2.x, times, 'ias15', obs_time_base), label = 'Nonlinear fit manual (jitter)')\n",
    "# plt.axvline(x = 54650, c='k', label = 'New data')\n",
    "# plt.xlabel('BJD - 2.4e6'), plt.ylabel('Radial Velocity (m/s)')\n",
    "# plt.legend(loc = 'lower left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check likelihood and compare:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log_likelihood(fit_params), neg_log_likelihood(best_fit_jitter.x)# , neg_log_likelihood(best_fit_jitter2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params, best_fit_jitter.x# , best_fit_jitter2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a 2D grid of $S$ and jitter scale factors, then for each point hold them constant while optimizing the parameters using least-squares (or nonlinear) and compute the likelihood "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njitter, nlib = (50, 50)  # can change this\n",
    "# create jitter and A_0 points\n",
    "jitter_sfs = np.linspace(0., 4, njitter)  # use 1 to 6 for jitter as recommended\n",
    "Alibs = np.linspace(1., 0.05, nlib)  # use Alib 1 to 0.05\n",
    "# create meshgrid\n",
    "jitter_sfs_grid, Alibs_grid = np.meshgrid(jitter_sfs, Alibs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the parameters using least squares while holding $A_{0}$ and jitter constant for each point, then compute the likelihood ($\\chi^2$) just of the fit for each point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rvs_jitter(params, jitter_sf, times, integrator, time_base, auday_ms = AUDAY_MS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets RVs from a Numpy array of planet params, taking into account a jitter term\n",
    "    \n",
    "    param params:     for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i) (also params[-4])\n",
    "    \n",
    "    param jitter: constant jitter scale factor\n",
    "    param times: array of times to integrate over\n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    sim = get_sim_from_params(params, integrator, time_base = time_base)\n",
    "    \n",
    "    sim_backwards = sim.copy()\n",
    "    sim_backwards.dt *= -1  # set timestep to be negative if integrating backwards\n",
    "\n",
    "    times = pd.Series(times)  # convert to series if not already\n",
    "    \n",
    "    forward_times = times[times - obs_time_base >= 0]\n",
    "    backward_times = times[times - obs_time_base < 0]\n",
    "    forward_indices = forward_times.index\n",
    "    backward_indices = backward_times.index\n",
    "    \n",
    "    # initialize rvs\n",
    "    rv_forward = np.zeros(len(forward_times))\n",
    "    rv_backward = np.zeros(len(backward_times))\n",
    "    \n",
    "    num_planets = 2  # find number of planets in params passed\n",
    "    \n",
    "    # get the rvs (z velocity, assuming 90 deg inclination) from the rebound simulation to compare with the actual simulation\n",
    "    for j, it in enumerate(zip(forward_indices, forward_times)):\n",
    "        i, t = it  # forward index, forward time\n",
    "        sim.integrate(t, exact_finish_time = 1)\n",
    "        # integrate to the specified time, exact_finish_time = 1 for ias15, \n",
    "        # sim.status()\n",
    "        star = sim.particles[0]\n",
    "        # print(instrument[i])\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_forward[j] = (-star.vz * auday_ms) + rv_offset  # use x-velocity of the star as the radial velocity, convert to m/s\n",
    "    \n",
    "    for j, it in enumerate(zip(backward_indices, backward_times)):\n",
    "        i, t = it  # backward index, backward time\n",
    "        sim_backwards.integrate(t, exact_finish_time = 1)\n",
    "        star = sim_backwards.particles[0]\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        # print(instrument[i])\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_backward[j] = (-star.vz * auday_ms) + rv_offset\n",
    "    \n",
    "    return np.concatenate((rv_backward, rv_forward))\n",
    "\n",
    "\n",
    "def get_nbody_resids_jitter_libration(params, jitters, Alib, nperiods=500, nsamples=1000, integrator='ias15', data=hd_data, time_base=obs_time_base):\n",
    "    \"\"\"\n",
    "    Gets the normalized residuals for the n-body fit with REBOUND, penalizing for the RMS of the libration angle a \n",
    "    and for jitter, holding each of them constant (this is the function we want to optimize)\n",
    "    \n",
    "    params is in the form of params for the 10-param model (n-body rebound) rather than the 7-param equilibrium model (keplerian)\n",
    "    \n",
    "    Alib is 0.01 by default\n",
    "    \"\"\"\n",
    "\n",
    "    obs_y = data.RV_mlc_nzp  # observed RVs\n",
    "    synth_y = get_rvs(params, data.target, data.BJD, 'ias15', time_base = obs_time_base)  # RVs from the rebound simulation\n",
    "    obs_yerr = data.e_RV_mlc_nzp  # y error\n",
    "\n",
    "    # get numpy array of jitters corresponding to each instrument\n",
    "    conditions = [data.target == 'HARPS1', data.target == 'HARPS2', data.target == 'HIRES']  # conditions are harps1, harps2 or hires\n",
    "    # get the jitter values for the corresponding data points\n",
    "    jitter = np.select(conditions, jitters, default=np.nan)\n",
    "\n",
    "    # then first compute the normalized residuals taking into account jitter, as follows:\n",
    "    jitter_normalized_resids = (obs_y - synth_y)/np.sqrt(obs_yerr ** 2 + jitter ** 2)  # compute normalized residuals using rebound\n",
    "    \n",
    "    # define p1\n",
    "    p1 = params[0]\n",
    "\n",
    "    angle_times = np.linspace(0, 0 + p1 * nperiods, nsamples)  # angle times, use length of observed rvs\n",
    "    angle_time_base = 0#np.median(angle_times)  # reset angle time base to something else to find the libration amplitude \n",
    "    # initialize sim\n",
    "    angle_sim = get_sim_from_params(params, integrator='whfast', time_base=0)\n",
    "    inner = angle_sim.particles[1]\n",
    "    outer = angle_sim.particles[2]\n",
    "    # define empty arrays\n",
    "    angle1, angle2 = np.zeros((2, nsamples))  # init empty arrays\n",
    "    # now compute the libration angle arrays\n",
    "    # test2 = np.zeros(len(angle_times))\n",
    "    for i, t in enumerate(angle_times):\n",
    "        angle_sim.integrate(t, exact_finish_time = 0)\n",
    "        resonant_angle = 3 * outer.l - 2 * inner.l  # 3*lambda_2 - 2*lambda_1\n",
    "        # test2[i] = resonant_angle\n",
    "        angle1[i] = np.mod(resonant_angle - inner.pomega, 2 * np.pi)  # 3*lambda_2 - 2*lambda_1 - pomega_1, mod 2pi\n",
    "        angle2[i] = np.mod(resonant_angle - outer.pomega, 2 * np.pi)  # 3*lambda_2 - 2*lambda_1 - pomega_2, mod 2pi\n",
    "    \n",
    "    # now return the rms libration amplitude for inner and outer to penalize by\n",
    "    # compute the normalized \"residuals\" A_lib_resids_1 (inner planet) and A_lib_resids_2 (outer planet)\n",
    "    A_lib_normalized_resids_1 = np.array([(angle - 0)/(Alib * np.sqrt(len(angle1))) \n",
    "                     for angle in [angle - 2 * np.pi if angle > np.pi else angle for angle in angle1]])  # since inner planet oscillates around 0\n",
    "    A_lib_normalized_resids_2 = np.array([(angle - np.pi)/(Alib * np.sqrt(len(angle2))) for angle in angle2])  # since outer planet oscillates around pi\n",
    "\n",
    "    # return normalized residuals plus the \"residuals\" used for the RMS libration amplitude penalty\n",
    "    return np.concatenate((jitter_normalized_resids, A_lib_normalized_resids_1, A_lib_normalized_resids_2))  # concatenate all 3 arrays to pass to the least squares optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to make sure it's computing residuals properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_jitters = best_fit_jitter.x[-3:]\n",
    "\n",
    "test_resids = get_nbody_resids_jitter_libration(best_fit_jitter.x, jitters=jitter_sfs_grid[0, 1] * test_jitters, Alib=Alibs_grid[0, 1])\n",
    "neg_log_likelihood(best_fit_jitter.x), (test_resids @ test_resids)/2  # neg log likelihood has an extra constant term added to it so it may be higher than the test resids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_resids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And optimize the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds2 = ([-np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, -np.inf, 0, -np.inf, -np.inf, -np.inf],\n",
    "          [np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, np.inf, 1, np.inf, np.inf, np.inf])\n",
    "\n",
    "fit_param_jitters = np.array(fit_params[-3:])  # fit param jitters are the last 3 entries in the array\n",
    "test_fit_params = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, \n",
    "                                                                                          jitters = fit_param_jitters * jitter_sfs_grid[0, 1], \n",
    "                                                                                          Alib=Alibs_grid[0, 1]), fit_params, bounds=bounds2)\n",
    "test_fit_params.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fit_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing likelihoods over the $A_0$-jitter grid:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for a single iteration of the loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njitter, nlib = (50, 50)  # can change this\n",
    "# create jitter and A_0 points\n",
    "jitter_sfs = np.linspace(0., 4, njitter)  # use 0 to 4 for jitter scale factor as recommended\n",
    "Alibs = np.linspace(1., 0.05, nlib)  # use Alib 1 to 0.05\n",
    "# create meshgrid\n",
    "jitter_sfs_grid, Alibs_grid = np.meshgrid(jitter_sfs, Alibs)\n",
    "\n",
    "x0 = fit_params\n",
    "best_fit_jitters = best_fit_jitter.x[-3:]  # these are the best fit jitter values\n",
    "neg_log_likelihoods = np.zeros((njitter, nlib))\n",
    "\n",
    "Alib = Alibs_grid[0, 1]  \n",
    "jitters = jitter_sfs_grid[0, 1] * best_fit_jitters\n",
    "# optimize the parameters, holding Alib and jitter scale factor constant at the specified grid point\n",
    "Alib_jitter_fit_params = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitters=jitters, Alib=Alib), \n",
    "                                                x0, bounds=bounds2, ftol=1e-8, xtol=1e-8).x\n",
    "# then compute the negative log likelihood of fit just from the parameters (not the total cost function including the libration penalty term)\n",
    "# assuming the jitter scale factor used in the optimization\n",
    "Alib_jitter_fit_params[-3:] = jitters\n",
    "# plug params into negative log likelihood and record it\n",
    "neg_log_likelihoods[0, 1] = neg_log_likelihood(Alib_jitter_fit_params)\n",
    "# update fit params with previous value\n",
    "x0 = Alib_jitter_fit_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now optimize the parameters for each given value of $A_0$ and jitter, computing the likelihood $\\mathfrak{L}$, for a jitter scale factor from $0.1$ to $4$, to show the contours for hgih jitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njitter, nlib = (50, 50)  # can change this\n",
    "# create jitter and A_0 points\n",
    "jitter_sfs = np.linspace(0.1, 4, njitter)  # use 0.1 to 4 for jitter scale factor as recommended\n",
    "Alibs = np.linspace(1., 0.05, nlib)  # use Alib 1 to 0.05\n",
    "# create meshgrid\n",
    "jitter_sfs_grid, Alibs_grid = np.meshgrid(jitter_sfs, Alibs)\n",
    "\n",
    "x0 = fit_params\n",
    "best_fit_jitters = best_fit_jitter.x[-3:]  # these are the best fit jitter values \n",
    "\n",
    "# they are constant and are scaled by some uniform jitter scaling factor in the loop, and held constant during the optimization procedure\n",
    "# neg_log_likelihoods = np.zeros((njitter, nlib))\n",
    "# for i in tqdm(range(njitter)):\n",
    "#     # add something here to reset the original guess which could maybe speed it up a bit\n",
    "#     for j in range(nlib):\n",
    "#         # get the A0, jitter scale factor point on the grid and then multiply the best-fit jitters by the scale factor\n",
    "#         Alib = Alibs_grid[i, j]  \n",
    "#         jitters = jitter_sfs_grid[i, j] * best_fit_jitters\n",
    "#         # optimize the parameters, holding Alib and jitter scale factor constant at the specified grid point\n",
    "#         Alib_jitter_fit_params = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitters=jitters, Alib=Alib), \n",
    "#                                                         x0, bounds=bounds2, ftol=1e-8, xtol=1e-8).x\n",
    "#         # then compute the negative log likelihood of fit just from the parameters (not the total cost function including the libration penalty term)\n",
    "#         # assuming the jitter scale factor used in the optimization\n",
    "#         Alib_jitter_fit_params[-3:] = jitters\n",
    "#         # plug params into negative log likelihood and record it\n",
    "#         neg_log_likelihoods[i, j] = neg_log_likelihood(Alib_jitter_fit_params)\n",
    "#         # update fit params with previous value\n",
    "#         x0 = Alib_jitter_fit_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save/load the neg log likelihoods (uncomment following code if need to save/load...):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('neg_log_likelihoods_everything_contours', neg_log_likelihoods) # save the neg log likelihood array in numpy\n",
    "neg_log_likelihoods = np.load('neg_log_likelihoods_everything_contours.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And computing neg log likelihoods for $0.02$-$2$ jitter scale factor to show the contours for low jitter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "njitter_02, nlib_02 = (50, 50) \n",
    "# create jitter, A_0 points\n",
    "jitter_sfs_02 = np.linspace(0.02, 2., njitter_02)  # use 0 to 0.5 for jitter\n",
    "Alibs_02 = np.linspace(1., 0.05, nlib_02)\n",
    "# Alibs_05 = 1.05 - np.geomspace(1, 0.05)  # use Alib 1 to 0.05\n",
    "# create meshgrid\n",
    "jitter_sfs_grid_02, Alibs_grid_02 = np.meshgrid(jitter_sfs_02, Alibs_02)\n",
    "# this now takes only ~40 minutes, not too bad...\n",
    "\n",
    "x0_02 = fit_params\n",
    "best_fit_jitters_02 = best_fit_jitter.x[-3:]\n",
    "\n",
    "# # same as before\n",
    "# neg_log_likelihoods_02 = np.zeros((njitter_02, nlib_02))\n",
    "# for i in tqdm(range(njitter_02)):\n",
    "#     # add something here to reset the original guess which could maybe speed it up a bit\n",
    "#     for j in range(nlib_02):\n",
    "#         # get the A0, jitterpoint on the grid\n",
    "#         Alib_02 = Alibs_grid_02[i, j]  \n",
    "#         jitters_02 = jitter_sfs_grid_02[i, j] * best_fit_jitters\n",
    "#         # optimize the parameters, holding A0 and jitter constant at the specified grid point\n",
    "#         # set the f and x tolerance to be much lower!\n",
    "#         Alib_jitter_fit_params_02 = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitters=jitters_02, Alib=Alib_02), \n",
    "#                                                            x0_02, bounds=bounds2, ftol=1e-8, xtol=1e-8).x\n",
    "#         # then compute the negative log likelihood of fit just from the parameters (not the total cost function including the libration penalty term)\n",
    "#         # add jitter back to the parameters\n",
    "#         Alib_jitter_fit_params_02[-3:] = jitters_02 \n",
    "#         # plug params into negative log likelihood and record it\n",
    "#         neg_log_likelihoods_02[i, j] = neg_log_likelihood(Alib_jitter_fit_params_02)\n",
    "#         # update fit params with previous value\n",
    "#         x0_02 = Alib_jitter_fit_params_02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Save/load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# np.save('neg_log_likelihoods_everything_02', neg_log_likelihoods_02)\n",
    "\n",
    "# load\n",
    "neg_log_likelihoods_02 = np.load('neg_log_likelihoods_everything_02.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for $0.5$-$2$ jitter scale factor:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors\n",
    "import matplotlib.cm\n",
    "\n",
    "def rgb_white2alpha(rgb, ensure_increasing=False):\n",
    "    \"\"\"\n",
    "    Convert a set of RGB colors to RGBA with maximum transparency.\n",
    "    \n",
    "    The transparency is maximised for each color individually, assuming\n",
    "    that the background is white.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rgb : array_like shaped (N, 3)\n",
    "        Original colors.\n",
    "    ensure_increasing : bool, default=False\n",
    "        Ensure that alpha values are strictly increasing.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rgba : numpy.ndarray shaped (N, 4)\n",
    "        Colors with maximum possible transparency, assuming a white\n",
    "        background.\n",
    "    \"\"\"\n",
    "    # The most transparent alpha we can use is given by the min of RGB\n",
    "    # Convert it from saturation to opacity\n",
    "    alpha = 1. - np.min(rgb, axis=1)\n",
    "    if ensure_increasing:\n",
    "        # Let's also ensure the alpha value is monotonically increasing\n",
    "        a_max = alpha[0]\n",
    "        for i, a in enumerate(alpha):\n",
    "            alpha[i] = a_max = np.maximum(a, a_max)\n",
    "    alpha = np.expand_dims(alpha, -1)\n",
    "    # Rescale colors to discount the white that will show through from transparency\n",
    "    rgb = (rgb + alpha - 1) / alpha\n",
    "    # Concatenate our alpha channel\n",
    "    return np.concatenate((rgb, alpha), axis=1)\n",
    "\n",
    "def cmap_white2alpha(name, ensure_increasing=False, register=True):\n",
    "    \"\"\"\n",
    "    Convert colormap to have the most transparency possible, assuming white background.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        Name of builtin (or registered) colormap.\n",
    "    ensure_increasing : bool, default=False\n",
    "        Ensure that alpha values are strictly increasing.\n",
    "    register : bool, default=True\n",
    "        Whether to register the new colormap.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cmap : matplotlib.colors.ListedColormap\n",
    "        Colormap with alpha set as low as possible.\n",
    "    \"\"\"\n",
    "    # Fetch the cmap callable\n",
    "    cmap = plt.get_cmap(name)\n",
    "    # Get the colors out from the colormap LUT\n",
    "    rgb = cmap(np.arange(cmap.N))[:, :3]  # N-by-3\n",
    "    # Convert white to alpha\n",
    "    rgba = rgb_white2alpha(rgb, ensure_increasing=ensure_increasing)\n",
    "    # Create a new Colormap object\n",
    "    cmap_alpha = matplotlib.colors.ListedColormap(rgba, name=name + \"_alpha\")\n",
    "    if register:\n",
    "        matplotlib.cm.register_cmap(name=name + \"_alpha\", cmap=cmap_alpha)\n",
    "    return cmap_alpha\n",
    "\n",
    "# Get original Reds colormap\n",
    "cmap_og = plt.get_cmap(\"Reds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib.ticker import MultipleLocator\n",
    "# # load data\n",
    "# neg_log_likelihoods_02 = np.load('neg_log_likelihoods_everything_02.npy')\n",
    "# # minimum neg log likelihood at zero jitter\n",
    "# min_neg_log_likelihood_02 = neg_log_likelihoods_02[5, 0] \n",
    "# # locations of contour labels\n",
    "# # manual_locations = [(2.4, 0.7), (1.7, 0.6), (2.0, 0.6), (3.3, 0.6), (3.9, 0.6)]\n",
    "# # levels\n",
    "# levels_02 = [min_neg_log_likelihood_02 + 1, min_neg_log_likelihood_02 + 4, min_neg_log_likelihood_02 + 9]\n",
    "\n",
    "# import scipy.ndimage\n",
    "# sigma = 1.\n",
    "# neg_log_likelihoods_02 = scipy.ndimage.filters.gaussian_filter(neg_log_likelihoods_02, sigma)\n",
    "\n",
    "# njitter_02, nlib_02 = (50, 50) \n",
    "# jitters_02 = np.linspace(0., 0.2, njitter_02)  # use 0 to 0.5 for jitter\n",
    "# Alibs_02 = np.linspace(1.1, 0.05, nlib_02)\n",
    "# jitters_grid_02, Alibs_grid_02 = np.meshgrid(jitters_02, Alibs_02)\n",
    "\n",
    "# # plotting\n",
    "# fig_, ax = plt.subplots(nrows=1, ncols=1, figsize = (12, 9), dpi=100)\n",
    "# fig3 = plt.contourf(jitters_grid_02, Alibs_grid_02, neg_log_likelihoods_02, cmap=plt.get_cmap('Blues_r'), alpha=1., \n",
    "#                     antialiased=True, levels=levels_02, extend='min')\n",
    "# plt.scatter(jitters_grid_02[5, 0], Alibs_grid_02[5, 0], label = 'Best fit', color='red', s=50)\n",
    "# plt.annotate(f'{np.round(min_neg_log_likelihood_02, 2)}', xy=(jitters_grid_02[5, 0], Alibs_grid_02[5, 0]), \n",
    "#               xycoords='data', textcoords='axes fraction', xytext=(0.005, 0.95), color='red')\n",
    "# plt.xlabel('jitter (m/s)'), plt.ylabel(r'$S$')\n",
    "# # plt.clabel(fig3, inline=True, fontsize=14)#, manual=manual_locations)\n",
    "# plt.ylim(top=1.)\n",
    "# plt.tick_params('both', length=6, width=1.5, which='major')\n",
    "# plt.tick_params('both', length=3, width=0.75, which='minor')\n",
    "# ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "# ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "# # save\n",
    "# plt.savefig('2021_fall-2022_winter/paper_figures/Alib_jitter_sini_contour_0_02.png')#, fmt='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Figure in paper; Alib-jitter plot \n",
    "\n",
    "Methodology: \n",
    "- Take full set of planet parameters, but hold A_lib and jitter constant across a grid of values\n",
    "- Optimize the function `get_nbody_results_jitter_libration()` which is the same least-squares function for RVs used, but with an additional penalty for the RMS libration amplitude, for each set of parameters\n",
    "- Then compute the negative log-likelihood of each set of parameters following Eq. 1 of (https://iopscience.iop.org/article/10.1088/0004-637X/794/1/51/pdf), which takes into account all parameters (including jitter) but not libration\n",
    "- Plot the best-fit point (lowest log-likelihood) and likelihood contours of best fit $\\mathcal{L}$ + ($1$, $4$, $9$) corresponding to ($1, 2, 3 \\sigma$) from best-fit likelihood\n",
    "\n",
    "Results strongly suggests nonzero jitter but shows that A_lib doesn't matter until a very strong penalty is applied (below $A \\approx 0.3$) and that the fit is better with a weaker penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(neg_log_likelihoods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels2 = [280, 285, 290, 295, 300]\n",
    "\n",
    "fig = plt.contour(jitter_sfs_grid_02, Alibs_grid_02, neg_log_likelihoods_02, levels = levels2, alpha = 0.9, antialiased=True)\n",
    "plt.xscale('log')\n",
    "plt.xlim(left=2e-2)\n",
    "plt.clabel(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_likelihood = np.min(neg_log_likelihoods)\n",
    "min_likelihood_index = tuple(np.argwhere(neg_log_likelihoods == min_likelihood).reshape(-1))\n",
    "jitter_sfs_grid[min_likelihood_index], Alibs_grid[min_likelihood_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import MultipleLocator\n",
    "import scipy.ndimage\n",
    "\n",
    "neg_log_likelihoods = np.load('neg_log_likelihoods_everything_contours.npy')\n",
    "neg_log_likelihoods_02 = np.load('neg_log_likelihoods_everything_02.npy')\n",
    "\n",
    "# neg_log_likelihoods = scipy.ndimage.filters.gaussian_filter(neg_log_likelihoods, sigma=1.2)# [5:,:]\n",
    "\n",
    "neg_log_likelihoods = scipy.ndimage.filters.gaussian_filter(neg_log_likelihoods, sigma=0.)\n",
    "neg_log_likelihoods_02 = scipy.ndimage.filters.gaussian_filter(neg_log_likelihoods_02, sigma=1.)\n",
    "\n",
    "# neg_log_likelihoods = scipy.ndimage.zoom(neg_log_likelihoods, zoom=3)\n",
    "\n",
    "# jitters_0_05 = np.linspace(0., 0.2, 50)\n",
    "# Alibs_0_05 = np.linspace(1.1, 0.05, 50)\n",
    "# jitters_grid_0_05, Alibs_grid_0_05 = np.meshgrid(jitters_0_05, Alibs_0_05)\n",
    "# neg_log_likelihoods_0_05 = scipy.ndimage.filters.gaussian_filter(neg_log_likelihoods_02, sigma=1.)\n",
    "\n",
    "# min_likelihood = 144.46\n",
    "min_likelihood = np.min(neg_log_likelihoods)\n",
    "min_likelihood_index = tuple(np.argwhere(neg_log_likelihoods == min_likelihood).reshape(-1))\n",
    "\n",
    "# min_likelihood_zero_jitter = np.min(neg_log_likelihoods_0_05[:,0])\n",
    "\n",
    "# levels\n",
    "levels = [min_likelihood + 1, min_likelihood + 4, min_likelihood + 9]\n",
    "# levels = [min_likelihood + 1, min_likelihood + 4, min_likelihood + 9, \n",
    "#                             min_likelihood + 16, min_likelihood + 25, min_likelihood + 36, \n",
    "#                             min_likelihood + 49, min_likelihood + 64, min_likelihood + 81, \n",
    "#                             min_likelihood + 100]\n",
    "levels2 = [min_likelihood + 11. ** 2, min_likelihood + 11.25 ** 2, min_likelihood + 11.55 ** 2, min_likelihood + 11.75 ** 2,\n",
    "           min_likelihood + 12. ** 2]#, min_likelihood + 11.5 ** 2]#, min_likelihood + 11.5 ** 2]\n",
    "\n",
    "njitter, nlib = (50, 50)  # can change this\n",
    "# create jitter and A_0 points\n",
    "jitter_sfs = np.linspace(0.1, 4, njitter)  # use 0 to 4 for jitter scale factor as recommended\n",
    "Alibs = np.linspace(1., 0.05, nlib)  # use Alib 1 to 0.05\n",
    "# create meshgrid\n",
    "jitter_sfs_grid, Alibs_grid = np.meshgrid(jitter_sfs, Alibs)\n",
    "\n",
    "njitter_02, nlib_02 = (50, 50) \n",
    "# create jitter, A_0 points\n",
    "jitter_sfs_02 = np.linspace(0.02, 2., njitter_02)  # use 0 to 0.5 for jitter\n",
    "Alibs_02 = np.linspace(1., 0.05, nlib_02)\n",
    "# Alibs_05 = 1.05 - np.geomspace(1, 0.05)  # use Alib 1 to 0.05\n",
    "# create meshgrid\n",
    "jitter_sfs_grid_02, Alibs_grid_02 = np.meshgrid(jitter_sfs_02, Alibs_02)\n",
    "# this now takes only ~40 minutes, not too bad...\n",
    "\n",
    "# locations of contour labels\n",
    "manual_locations = [(2.4, 0.7), (1.7, 0.6), (2.0, 0.6), (3.3, 0.6), (3.9, 0.6)]\n",
    "\n",
    "# plotting\n",
    "plt.rc('font', size=20)\n",
    "fig_, ax = plt.subplots(nrows=1, ncols=1, figsize = (12, 9), dpi=100)\n",
    "plt.xscale('log')\n",
    "fig = plt.contourf(jitter_sfs_grid, Alibs_grid, neg_log_likelihoods, levels = levels, cmap=plt.get_cmap('Greys_r'), alpha=1., \n",
    "                   antialiased=True, extend='min', label='negative log likelihoods')\n",
    "fig = plt.contour(jitter_sfs_grid, Alibs_grid, neg_log_likelihoods, levels = levels, colors = 'r', alpha = 0.9, antialiased=True)\n",
    "fig2 = plt.contour(jitter_sfs_grid_02, Alibs_grid_02, neg_log_likelihoods_02, levels = levels2, colors='r', alpha = 0.9, antialiased=True)\n",
    "# fig3 = plt.contour(jitters_grid_02, Alibs_grid_02, neg_log_likelihoods_02, levels = levels2)\n",
    "# fig2 = plt.contour(jitters_grid_05, Alibs_grid_05, neg_log_likelihoods_05, levels = [396, 397, 397.5])\n",
    "\n",
    "plt.scatter(jitter_sfs_grid[min_likelihood_index], Alibs_grid[min_likelihood_index], label = 'Best fit', color='darkorange', s=150)\n",
    "# plt.annotate(f'{np.round(min_likelihood, 2)}', xy=(jitters_grid[min_likelihood_index], Alibs_grid[min_likelihood_index]), \n",
    "#               xycoords='data', textcoords='axes fraction', xytext=(0.45, 0.95), color='red')\n",
    "plt.xlabel('jitter scale factor'), plt.ylabel(r'$S$')\n",
    "# plt.clabel(fig, inline=True, fontsize=28, colors='k')#, manual=manual_locations)\n",
    "\n",
    "low_fmt = {}\n",
    "high_fmt = {}\n",
    "strs_low = [r'$11\\sigma$', r'$11.25\\sigma$', r'$11.5\\sigma$', r'$11.75\\sigma$', r'$12\\sigma$']\n",
    "strs_high = [r'$1\\sigma$', r'$2\\sigma$', r'$3\\sigma$']\n",
    "for l, s in zip(levels2, strs_low):\n",
    "    low_fmt[l] = s\n",
    "for l, s in zip(levels, strs_high):\n",
    "    high_fmt[l] = s\n",
    "\n",
    "# Basic contour plot\n",
    "# plt.clabel(fig3, inline=True, fontsize=14)\n",
    "# yticks\n",
    "ax.tick_params('both', length=12, width=1.5, which='major')\n",
    "ax.tick_params('both', length=6, width=0.8, which='minor')\n",
    "ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "ax.yaxis.set_minor_locator(MultipleLocator(0.05))\n",
    "plt.xlim(left=3e-2)\n",
    "plt.ylim(top=1.)\n",
    "plt.gca().clabel(fig, inline=True, fmt=high_fmt, fontsize=16)\n",
    "plt.gca().clabel(fig2, inline=True, fmt=low_fmt, fontsize=16)\n",
    "# plt.legend(loc='upper right')\n",
    "plt.savefig('2021_fall-2022_winter/paper_figures/Alib_jitter_sini_contour_05_5.png')#, fmt='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg_log_likelihoods = np.load('neg_log_likelihoods_everything_contours.npy')\n",
    "fig, ax = plt.subplots(1, 1, figsize = (12, 8), dpi=100)\n",
    "plt.scatter(Alibs, neg_log_likelihoods[:,min_likelihood_index[-1]])\n",
    "ax.hlines(levels, cmap=plt.get_cmap('Blues_r'), alpha=1., xmin=0., xmax=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(1, 1, figsize = (12, 8), dpi=100)\n",
    "# plt.scatter(Alibs_02[5:], neg_log_likelihoods_02[5:, 5])\n",
    "# ax.hlines(levels_02, cmap=plt.get_cmap('Blues_r'), alpha=1., xmin=0., xmax=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the approximate value of $1\\sigma_\\text{jit}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitter_range = jitters_grid[0][[np.argwhere(neg_log_likelihoods[0] < np.min(neg_log_likelihoods[0] + 1))]]\n",
    "# onesigma_jit = (np.max(jitter_range) - np.min(jitter_range))/2\n",
    "# onesigma_jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Testing/Debugging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Now compute and plot the likelihood for varying $A_0$ while holding jitter at $0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlib = 150\n",
    "Alibs = np.linspace(1.1, 0.05, nlib)\n",
    "\n",
    "neg_log_likelihoods_zero_jitter = np.zeros(nlib)\n",
    "\n",
    "x0 = fit_params\n",
    "for j in tqdm(range(nlib)):\n",
    "    # get the A0, jitter point on the grid\n",
    "    Alib = Alibs[j]  \n",
    "    jitter = 0.\n",
    "    # optimize the parameters, holding A0 and jitter constant at the specified grid point\n",
    "    Alib_jitter_fit_params = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitter=jitter, Alib=Alib), \n",
    "                                                    x0, bounds=bounds2, ftol=1e-12, xtol=1e-12, verbose=0).x\n",
    "    # then compute the negative log likelihood of fit just from the parameters (not the total cost function including the libration penalty term)\n",
    "    # add jitter back to the parameters\n",
    "    Alib_jitter_fit_params[-1] = jitter \n",
    "    # plug params into negative log likelihood and record it\n",
    "    neg_log_likelihoods_zero_jitter[j] = neg_log_likelihood(Alib_jitter_fit_params)\n",
    "    # update fit params with previous value\n",
    "    x0 = Alib_jitter_fit_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Save/load:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# np.save('neg_log_likelihoods_zero_jitter', neg_log_likelihoods_zero_jitter)\n",
    "\n",
    "# load\n",
    "neg_log_likelihoods_zero_jitter = np.load('neg_log_likelihoods_zero_jitter.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(Alibs, neg_log_likelihoods_zero_jitter)\n",
    "plt.xlim(right=1.)\n",
    "# plt.ylim(396, 399)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Alibs[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fit_params = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitter=0., Alib=Alibs[75]), \n",
    "                                                fit_params, bounds=bounds2, verbose=0).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fit_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fit_params[-1] = 0\n",
    "neg_log_likelihood(test_fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "sim = get_sim_from_params(test_fit_params, integrator='ias15', time_base=obs_time_base)\n",
    "op = rb.OrbitPlot(sim, orbit_style='solid', color=True)\n",
    "fig = op.fig\n",
    "for i in range(100):\n",
    "    op.sim.integrate(sim.t+1000)\n",
    "    op.update()       # update data\n",
    "    op.fig.savefig(\"op_frames/out_%02d.png\"%i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(cluster2samples[200:].reshape(-1, 13)[:,-1], cluster2log_prob[200:].reshape(-1))\n",
    "plt.ylim(-180, -140)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = h5py.File('mcmc_hd45364_test_everything_with_libration_penalty.h5', 'r')\n",
    "clusterdata = h5py.File('2021_fall-2022_winter/mcmc_hd45364_cluster_everything.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata, clusterdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusteraccepted, clustersamples, clusterlog_prob = np.array(clusterdata['mcmc']['accepted']), np.array(clusterdata['mcmc']['chain']), np.array(clusterdata['mcmc']['log_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testaccepted, testsamples, testlog_prob = np.array(testdata['mcmc']['accepted']), np.array(testdata['mcmc']['chain']), np.array(testdata['mcmc']['log_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterlog_prob[0], testlog_prob[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### extra:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing to make sure I can get a jacobian that's nonzero for every parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jacobian_fit_params = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration2(params, Alib=1, integrator='ias15'), best_fit_jitter2.x, bounds=bounds2)\n",
    "jacobian_fit_params = optimize.least_squares(lambda params: get_nbody_resids(params, integrator='ias15'), best_fit_jitter2.x, bounds=bounds2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jacobian_fit_params.x, best_fit_jitter2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = jacobian_fit_params.jac\n",
    "j[-1][-1] = onesigma_jit\n",
    "np.linalg.inv(j.T @ j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_log_likelihood(jacobian_fit_params.x), neg_log_likelihood(best_fit_jitter2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_yerr = hd_data.e_RV_mlc_nzp\n",
    "# jitter_penalties = [np.sum(np.log(np.sqrt(2 * np.pi * (obs_yerr ** 2 + jitter ** 2)))) for jitter in jitters]\n",
    "\n",
    "# plt.plot(jitters, jitter_penalties)\n",
    "\n",
    "# fit_params = np.array([ 2.28306953e+02,  7.26248510e+00,  5.39345613e+04,  4.02153494e-02,\n",
    "#        -1.76686411e-01,  3.43427379e+02,  1.79425723e+01,  5.40193481e+04,\n",
    "#         1.01456416e-01,  1.18819868e-01, -4.99414710e-01,  1.00000000e+00])\n",
    "\n",
    "# result = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitter=1, Alib=1), fit_params)\n",
    "\n",
    "# result2 = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitter=2, Alib=1), result.x)\n",
    "\n",
    "# result3 = optimize.least_squares(lambda params: get_nbody_resids_jitter_libration(params, jitter=3, Alib=1), result2.x)\n",
    "\n",
    "# result3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
