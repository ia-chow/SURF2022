{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68f47c4-1bcd-41a9-af67-99424ec58c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ichow9/.conda/envs/wmpl/lib/python3.10/site-packages/radvel/gp.py:32: ImportWarning: celerite not installed. GP kernals using celerite will not work. Try installing celerite using 'pip install celerite'\n",
      "  warnings.warn(\"celerite not installed. GP kernals using celerite will not work. \\\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import rebound as rb\n",
    "from matplotlib import pyplot as plt\n",
    "import celmech as cm\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import radvel\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy import optimize\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22386585-cdd1-40bd-8f27-9435079cabfb",
   "metadata": {},
   "source": [
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28fa7a7-2af4-4f16-97a0-a6c607f0e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAY_1_2015 = 57143.5  # barycentric julian date for May 1, 2015 (the date of the HARPS instrument upgrade as per trifonov et al 2020)\n",
    "# 57143.5 is BJD for May 1, 2015\n",
    "# 57173.5 is BJD for May 31, 2015\n",
    "\n",
    "# harps\n",
    "# hd_data_harps = pd.read_csv('hd45364_rvs.csv', sep = ';')\n",
    "hd_data_harps = pd.read_csv('HD45364_HARPS_RVBank_ver02.csv', sep=',')  # updated version\n",
    "# giant outlier at position 116 in the data (found manually earlier) which we remove\n",
    "hd_data_harps.drop(116, inplace=True)  # drop the row and keep the df in place\n",
    "# subtract 2.4e6 from all the rows in the data\n",
    "hd_data_harps.BJD -= 2.4e6\n",
    "# rename target to HARPS1 or HARPS2\n",
    "hd_data_harps['target'] = hd_data_harps.apply(lambda row: 'HARPS1' if row.BJD < MAY_1_2015 else 'HARPS2', axis = 1)\n",
    "# hires\n",
    "hd_data_hires = pd.read_csv('../hires_rvs.txt', sep = '\\t', index_col=False, header='infer', dtype=np.float64)\n",
    "hd_data_hires['BJD - 2,450,000'] += 50000.  # adding 50000 to have the same units as harps\n",
    "hd_data_hires['target'] = 'HIRES'\n",
    "hd_data_hires.columns = ['BJD', 'RV_mlc_nzp', 'e_RV_mlc_nzp', 'target']\n",
    "# concatenate two data sets one on top of the other\n",
    "hd_data = pd.concat((hd_data_harps, hd_data_hires), axis=0)  # matching BJD, RV_mlc_nzp and e_RV_mlc_nzp columns\n",
    "# reset index\n",
    "hd_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a030ce6-6d32-43c0-9e26-913c220bd6b9",
   "metadata": {},
   "source": [
    "Import posterior distribution for strong $A = 0.1$ penalty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbc58d1-75c1-4d15-b199-80fb117137d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the posterior distribution data for the STRONG PENALTY (A = 0.1)\n",
    "cluster_data = h5py.File('../mcmc_hd45364_everything_with_libration_penalty_variable_1.h5', 'r')  # import the posterior distribution data\n",
    "accepted, samples, log_prob = np.array(cluster_data['mcmc']['accepted']), np.array(cluster_data['mcmc']['chain']), np.array(cluster_data['mcmc']['log_prob'])\n",
    "n_burn_in = 200  # discard the first 200 samples as burn-in time\n",
    "# reshape the chain to flatten it out\n",
    "flat_samples = samples[n_burn_in:].reshape(-1, samples[n_burn_in:].shape[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c75a2-a534-4fb1-81ca-40f602db0bc2",
   "metadata": {},
   "source": [
    "Functions to analytically compute the $K$ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33710501-044f-432e-961d-553c2bdb5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very original parameters used in Hadden and Payne\n",
    "nbody_params =[ 2.27798546e+02,  7.25405874e+00,  5.39392010e+04,  1.71866112e-01, 1.17923823e-01,  \n",
    "               3.43881599e+02,  1.87692753e+01,  5.40138425e+04, 1.68408461e-01,  5.05903191e-02, \n",
    "               -3.28526403e-03, 0., 0., \n",
    "               1, \n",
    "               1.84, 0., 0.]  # inserted 0 for harps2 and hires for both rv offset and jitter\n",
    "\n",
    "# #Least squares fit: \n",
    "# fit_params = [ 2.28512793e+02, 7.27736501e+00, 5.39371914e+04, -4.66868256e-02, \n",
    "#                -1.78080009e-01, 3.43378038e+02, 1.78603341e+01, 5.40186750e+04, \n",
    "#                9.72945632e-02,  1.32194117e-01, -5.29072002e-01, 0., 0., 1, 2.428]#-7.68527759e-03] \n",
    "\n",
    "# Neg log likelihood jitter fit:\n",
    "prev_params = [ 2.27510047e+02,  7.21459722e+00, 5.39394197e+04, -1.45510376e-02, -1.91998583e-01,\n",
    "              3.44196007e+02,  1.80943200e+01,  5.47060928e+04, 9.38174624e-02,  1.11054397e-01,\n",
    "              -1.80048668e-01, -1.44155418e+00, 1.40493043e+00,\n",
    "              1.00000000e+00,\n",
    "              1.46046278e+00,  6.96508946e-01, 3.45217643e+00]\n",
    "\n",
    "# LI ET AL. 2022 PARAMS\n",
    "li_params = [225.34, 7.26, radvel.orbit.timeperi_to_timetrans(53375, 225.34, 0.07, np.deg2rad(92)), np.sqrt(0.07) * np.cos(np.deg2rad(92)), np.sqrt(0.07) * np.sin(np.deg2rad(92)),\n",
    "             345.76, 18.17, radvel.orbit.timeperi_to_timetrans(53336, 345.76, 0.01, np.deg2rad(276)), np.sqrt(0.01) * np.cos(np.deg2rad(276)), np.sqrt(0.01) * np.cos(np.deg2rad(276)),\n",
    "            -1.80048668e-01, -1.44155418e+00, 1.40493043e+00,\n",
    "              1.00000000e+00,\n",
    "              1.46046278e+00,  6.96508946e-01, 3.45217643e+00]\n",
    "\n",
    "# TRIFONOV PARAMS\n",
    "trifonov_params = [226.57, 7.29, radvel.orbit.timeperi_to_timetrans(52902, 226.57, 0.0796, np.deg2rad(244.44)), np.sqrt(0.0796) * np.cos(np.deg2rad(244.44)), np.sqrt(0.0796) * np.sin(np.deg2rad(244.44)),\n",
    "              344.66, 18.21, radvel.orbit.timeperi_to_timetrans(52920, 344.66, 0.002, np.deg2rad(20.342)), np.sqrt(0.0002) * np.cos(np.deg2rad(20.342)), np.sqrt(0.0002) * np.sin(np.deg2rad(20.342)),\n",
    "              0.041, -3.348, 2.708,\n",
    "              np.sin(np.deg2rad(83.7597)),\n",
    "              1.437, 0.763, 3.136]\n",
    "\n",
    "# UPDATED TRIFONOV PARAMS\n",
    "fit_params = [ 2.27879597e+02,  7.26670196e+00,  5.27997039e+04, -4.33392738e-02,\n",
    "       -2.20477279e-01,  3.44061366e+02,  1.82074627e+01,  5.29858704e+04,\n",
    "        9.68685024e-02,  2.30277928e-02, -3.66896966e-02, -3.32570314e+00,\n",
    "        1.74545697e+00,  1.00000000e+00,  1.40646019e+00,  6.94463892e-01,\n",
    "        3.00077415e+00]\n",
    "\n",
    "## CONSTANTS:\n",
    "\n",
    "# STAR_MASS = 920  # 920 jupiter masses\n",
    "STAR_MASS = 859\n",
    "G = 2.825e-7  # converting G to jupiter masses, au, and days\n",
    "AUDAY_MS = 1.731e6  # conversion factor for au/day to m/s\n",
    "\n",
    "obs_time_base = np.median(hd_data_harps.BJD)\n",
    "\n",
    "# print(f'nbody_params:{nbody_params}\\n fit_params:{fit_params}')\n",
    "\n",
    "def mass_to_semiamp(planet_mass, star_mass, period, eccentricity, inclination):\n",
    "    \"\"\"\n",
    "    planet mass (jupiter masses) to semi amplitude (in au/day)\n",
    "    \"\"\"\n",
    "    return ((2 * np.pi * G/period) ** (1/3) * (planet_mass * np.sin(inclination) / star_mass ** (2/3)) * (1/np.sqrt(1 - eccentricity ** 2)))\n",
    "\n",
    "\n",
    "def semiamp_to_mass(semiamp, star_mass, period, eccentricity, inclination):\n",
    "    \"\"\"\n",
    "    semi amplitude (in au/day) to planet mass (jupiter masses)\n",
    "    \"\"\"\n",
    "    return (((2 * np.pi * G/period) ** (-1/3)) * (semiamp / np.sin(inclination)) * np.sqrt(1 - eccentricity ** 2) * (star_mass ** (2/3)))\n",
    "\n",
    "\n",
    "def get_sim_from_params(params, integrator, time_base, star_mass = STAR_MASS, auday_ms = AUDAY_MS):\n",
    "    \"\"\"\n",
    "    takes in params array, returns a rebound Simulation object with those parameters\n",
    "    \n",
    "    param params: numpy array of params:\n",
    "    \n",
    "    for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i)\n",
    "    params[5 * num_planets + 4] is jitter for HARPS1\n",
    "    params[5 * num_planets + 5] is jitter for HARPS2\n",
    "    params[5 * num_planets + 6] is jitter for HIRES\n",
    "    \n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    param time_base: base time (to begin integration from) in the simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    num_planets = 2 # 2 planets\n",
    "    \n",
    "    sim = rb.Simulation()\n",
    "    sim.integrator = integrator\n",
    "    sim.t = time_base  # keplerian and n-body models initialized at the same time offset\n",
    "    # print(sim.t)\n",
    "    if integrator == 'whfast':  # if using whfast integrator, set timestep\n",
    "        sim.dt = 1/50 * np.min([params[0], params[5]])  # timestep is 1/20th of the shortest orbital period of any planet\n",
    "        # print(sim.dt)\n",
    "    sim.units = ('AU', 'Mjupiter', 'day')\n",
    "    sim.add(m = star_mass)  # star mass as a constant\n",
    "    \n",
    "    inclination = np.arcsin(params[-4])  # sin(i) is fourth from the back of the array\n",
    "        \n",
    "    for i in range (0, num_planets):\n",
    "        # print(i)\n",
    "        # planet parameters\n",
    "        period = params[5*i]  # in days\n",
    "        semiamp = params[5*i + 1] / auday_ms # divide by auday_ms because semiamp given in m/s\n",
    "        eccentricity = params[5*i + 3] ** 2 + params[5*i + 4] ** 2  # eccentricity from secos, sesin\n",
    "        omega = np.arctan2(params[5*i + 4], params[5*i + 3])  # omega from arctan of sesin, secos  (in that order!)\n",
    "        # get tp by converting from tc\n",
    "        tp = radvel.orbit.timetrans_to_timeperi(tc = params[5*i + 2], per = period, ecc = eccentricity, omega = omega)\n",
    "        \n",
    "        # mass\n",
    "        mass = semiamp_to_mass(semiamp = semiamp, star_mass = star_mass, period = period, eccentricity = eccentricity, inclination = inclination)\n",
    "        \n",
    "        # adding to simulation\n",
    "        sim.add(m = mass, P = period, e = eccentricity, T = tp, omega = omega, inc = inclination)\n",
    "        \n",
    "    sim.move_to_com()  # move to center of mass\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def get_simple_sim(masses, integrator = 'ias15', period_ratio = 3/2, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    gets simple sim (for eccentricity track stuff)\n",
    "    param masses: array of planet masses\n",
    "    param integrator: integrator\n",
    "    param epsilon: amount by which the resonant period ratio should be offset from the equilibrium in the simulation\n",
    "    \"\"\"\n",
    "    sim = rb.Simulation()\n",
    "    sim.integrator = integrator\n",
    "    # central star\n",
    "    sim.add(m = 1)\n",
    "    \n",
    "    sim.add(m = masses[0], P = 1)\n",
    "    sim.add(m = masses[1], P = period_ratio * (1 + epsilon))\n",
    "\n",
    "    sim.move_to_com()\n",
    "    if integrator == 'whfast':\n",
    "        sim.dt = 1/50 * 1  # dy default use 1/50th of the inner planet's orbital period for the timestep if using whfast\n",
    "    return sim\n",
    "\n",
    "\n",
    "def get_rvs(params, instrument, times, integrator, time_base, auday_ms = AUDAY_MS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets RVs from a Numpy array of planet params\n",
    "    \n",
    "    param params:     for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i) (also params[-4])\n",
    "    params[5 * num_planets + 4] is jitter for HARPS1 (also params[-3])\n",
    "    params[5 * num_planets + 5] is jitter for HARPS2 (also params[-2])\n",
    "    params[5 * num_planets + 6] is jitter for HIRES (also params[-1])\n",
    "\n",
    "    param instrument: instrument (HARPS1, HARPS2, or HIRES)\n",
    "    param times: array of times to integrate over\n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sim = get_sim_from_params(params, integrator, time_base = time_base)\n",
    "    \n",
    "    sim_backwards = sim.copy()\n",
    "    sim_backwards.dt *= -1  # set timestep to be negative if integrating backwards\n",
    "\n",
    "    times = pd.Series(times)  # convert to series if not already\n",
    "    \n",
    "    forward_times = times[times - time_base >= 0]\n",
    "    backward_times = times[times - time_base < 0]\n",
    "    forward_indices = forward_times.index\n",
    "    backward_indices = backward_times.index\n",
    "    \n",
    "    # initialize rvs\n",
    "    rv_forward = np.zeros(len(forward_times))\n",
    "    rv_backward = np.zeros(len(backward_times))\n",
    "    \n",
    "    num_planets = 2  # find number of planets in params passed\n",
    "    \n",
    "    # get the rvs (z velocity, assuming 90 deg inclination) from the rebound simulation to compare with the actual simulation\n",
    "    for j, it in enumerate(zip(forward_indices, forward_times)):\n",
    "        i, t = it  # forward index, forward time\n",
    "        sim.integrate(t, exact_finish_time = 1)\n",
    "        # integrate to the specified time, exact_finish_time = 1 for ias15, \n",
    "        # sim.status()\n",
    "        star = sim.particles[0]\n",
    "        # print(instrument[i])\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_forward[j] = (-star.vz * auday_ms) + rv_offset  # use x-velocity of the star as the radial velocity, convert to m/s\n",
    "    \n",
    "    for j, it in enumerate(zip(backward_indices, backward_times)):\n",
    "        i, t = it  # backward index, backward time\n",
    "        sim_backwards.integrate(t, exact_finish_time = 1)\n",
    "        star = sim_backwards.particles[0]\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        # print(instrument[i])\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_backward[j] = (-star.vz * auday_ms) + rv_offset\n",
    "    \n",
    "    return np.concatenate((rv_backward, rv_forward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce918154-e93a-406c-a5e4-2062e9184c7e",
   "metadata": {},
   "source": [
    "Functions to compute the best-fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdbe36b-50d4-4e0b-b6af-dbdcc4e37d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nbody_resids(params, integrator, data = hd_data):\n",
    "    \"\"\"\n",
    "    Gets the normalized residuals for the n-body fit with REBOUND\n",
    "    \"\"\"\n",
    "    obs_y = data.RV_mlc_nzp  # observed RVs\n",
    "    synth_y = get_rvs(params, data.target, data.BJD, integrator, time_base=obs_time_base)  # RVs from the rebound simulation\n",
    "    obs_yerr = data.e_RV_mlc_nzp  # y errors\n",
    "    return (obs_y - synth_y) / obs_yerr  # return normalized residuals\n",
    "\n",
    "\n",
    "def neg_log_likelihood(params, time_base = obs_time_base, data = hd_data, num_planets = 2):\n",
    "    \"\"\"\n",
    "    Gets the negative log-likelihood (including a jitter term!) for use with scipy.optimize.minimze\n",
    "    \n",
    "    Iplements the log likelihood using the same method above\n",
    "    \n",
    "    \"\"\"\n",
    "    obs_y = data.RV_mlc_nzp  # observed RVs\n",
    "    \n",
    "    # inclination not handled sparately\n",
    "    # inclination = np.arcsin(params[-4])  # inclination is np.arcsin of the second to last parameter\n",
    "    \n",
    "    synth_y = get_rvs(params, data.target, data.BJD, 'ias15', time_base = time_base)  # RVs from the rebound simulation\n",
    "    obs_yerr = data.e_RV_mlc_nzp  # y errors\n",
    "\n",
    "    conditions = [data.target == 'HARPS1', data.target == 'HARPS2', data.target == 'HIRES']  # conditions are harps1, harps2 or hires\n",
    "\n",
    "    rv_offsets = params[5 * num_planets:5 * num_planets + 3]  # rv_offsets for HARPS1, HARPS2 and HIRES, in that order\n",
    "    jitters = params[-3:]  # jitters for HARPS1, HARPS2 and HIRES, in that order\n",
    "    \n",
    "    # get the jitter and rv values for the corresponding data points\n",
    "    rv_offset = np.select(conditions, rv_offsets, default=np.nan)\n",
    "    jitter = np.select(conditions, jitters, default=np.nan)\n",
    "    # print(rv_offset, jitter)\n",
    "\n",
    "    # compute the log-likelihood\n",
    "    #### OLD\n",
    "    # log_likelihood = -1/2 * np.sum(((obs_y - synth_y) ** 2)/(obs_yerr ** 2 + jitter ** 2) \n",
    "    #                                + np.log(np.sqrt(2 * np.pi * (obs_yerr ** 2 + jitter ** 2))))\n",
    "\n",
    "    #### LI ET AL. 2022 VERSION (NEW)\n",
    "#     sigma_z2 = 1/(np.sum(1/(obs_yerr ** 2 + jitter ** 2)))\n",
    "    log_likelihood = -1/2 * np.sum(((obs_y - synth_y) ** 2)/((obs_yerr ** 2 + jitter ** 2))) - np.sum(np.log(np.sqrt(2 * np.pi * (obs_yerr ** 2 + jitter ** 2)))) # + np.log(np.sqrt(2 * np.pi * sigma_z2))\n",
    "    # log_likelihood = -1/2 * np.sum(np.log(variance) + ((obs_y - synth_y) ** 2/variance))    \n",
    "    # print(-1/2 * np.sum(((obs_y - rv_offset - synth_y) ** 2)/((obs_yerr ** 2 + jitter ** 2))))\n",
    "    # print(-log_likelihood)\n",
    "    return -log_likelihood  # negative since we are trying to minimize the negative log likelihood\n",
    "\n",
    "\n",
    "def get_tau_alphas(tau_alpha, m_inner, m_outer, period_ratio):\n",
    "    # use Kepler's third law to compute the ratio of semi-major axes in resonance from the period ratio in resonance\n",
    "    sma_ratio = period_ratio ** (2 / 3)  # ratio of outer planet's semi-major axis to inner\n",
    "    # define matrix A\n",
    "    A = np.array([[-1, 1],\n",
    "                  [m_outer, m_inner * sma_ratio]])\n",
    "    # compute gamma_1 and gamma_2\n",
    "    gammas = np.matmul(np.linalg.inv(A), np.array([-1 / tau_alpha, 0]))\n",
    "    # gamma = 1/tau\n",
    "    taus = 1 / gammas\n",
    "\n",
    "    return tuple(taus)  # returns (tau_alpha_outer, tau_alpha_inner) as a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29c6d9-4505-4ac3-a98f-224e606b7ebf",
   "metadata": {},
   "source": [
    "Function computing $K$ from $D$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69d55be-894f-4669-9e12-4cf2ac8b561c",
   "metadata": {},
   "source": [
    "\\begin{multline}\n",
    "     \\frac{d}{dt}\\mathcal{D}\\bigg|_\\mathrm{dis} =  0\n",
    "     \\\\\n",
    "     \\approx - \\frac{\\beta_1\\sqrt\\alpha e_b^2}{\\tau_{e, 1}} - \\frac{\\beta_2 e_2^2}{\\tau_{e, 2}} + \\frac{\\beta_1\\beta_2\\sqrt{\\alpha}}{3\\left(j\\beta_b\\sqrt{\\alpha} + (j-1)\\beta_c\\right)}\\frac{3}{2\\tau_\\alpha},\n",
    "\\end{multline}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90d2d3d-59e6-48c6-a060-9f978806cf27",
   "metadata": {},
   "source": [
    "$e_i$ are the planets' eccentricities, $\\beta_i=m_i/(m_1+m_2)$, $\\alpha \\approx \\left(\\frac{j-1}{j}\\right)^{2/3}$ is the pair's semi-major axis ratio, and $\\Delta = \\frac{j-1}{j}\\frac{P_2}{P_1} - 1$ measures the pair's fractional deviation from exact period ratio commensurability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c85c394-4a2d-4617-ab57-78256b4b6f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1, beta_2, alpha, e1, e2, tau_e1, tau_e2, j, tau_alpha, tau_e, K = sp.symbols('beta_1, beta_2, alpha, e_1, e_2, tau_e_1, tau_e_2, j, tau_alpha, tau_e, K')\n",
    "\n",
    "ddot_dis = -(beta_1 * sp.sqrt(alpha) * (e1 ** 2))/(tau_e1) - (beta_2 * (e2) ** 2)/(tau_e2) + (beta_1 * beta_2 * sp.sqrt(alpha))/(3 * (j *  beta_1 * sp.sqrt(alpha) + (j - 1) * beta_2)) * (3/(2 * tau_alpha))\n",
    "# j and alpha are always the same\n",
    "j_val = 3.  # 3:2 MMR\n",
    "alpha_val = ((j_val - 1)/(j_val)) ** (2./3.)\n",
    "ddot_dis_eq = ddot_dis.subs([(alpha, alpha_val), (j, j_val)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "678c6420-2bda-49a0-965b-f938d99f1f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\frac{1.31037069710445 \\beta_{1} \\beta_{2}}{\\tau_{\\alpha} \\left(7.86222418262669 \\beta_{1} + 6.0 \\beta_{2}\\right)} - \\frac{0.873580464736299 \\beta_{1} e_{1}^{2}}{\\tau_{e 1}} - \\frac{\\beta_{2} e_{2}^{2}}{\\tau_{e 2}}$"
      ],
      "text/plain": [
       "                                                               2        2\n",
       "       1.31037069710445⋅β₁⋅β₂           0.873580464736299⋅β₁⋅e₁    β₂⋅e₂ \n",
       "───────────────────────────────────── - ──────────────────────── - ──────\n",
       "τₐₗₚₕₐ⋅(7.86222418262669⋅β₁ + 6.0⋅β₂)             τₑ ₁              τₑ ₂ "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddot_dis_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8295e5a5-feeb-489b-8cc3-3df4732ae48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.27879590e+02,  7.26670160e+00,  5.27997040e+04, -4.33386844e-02,\n",
       "       -2.20477255e-01,  3.44061367e+02,  1.82074511e+01,  5.29858704e+04,\n",
       "        9.68672855e-02,  2.30292860e-02, -3.66891824e-02, -3.32569568e+00,\n",
       "        1.74545959e+00,  1.00000000e+00,  1.40646262e+00,  6.94455499e-01,\n",
       "        3.00076641e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ecc_con1(params):\n",
    "    return 1 - (params[3] ** 2 + params[4] ** 2)\n",
    "\n",
    "def ecc_con2(params):\n",
    "    return 1 - (params[8] ** 2 + params[9] ** 2)\n",
    "\n",
    "cons = ({'type': 'ineq', 'fun': ecc_con1}, \n",
    "        {'type': 'ineq', 'fun': ecc_con2})\n",
    "\n",
    "# bounds of (0, 1) for sin(i), everything else can vary however\n",
    "bounds = ((None, None), (None, None), (None, None), (None, None), (None, None), \n",
    "          (None, None), (None, None), (None, None), (None, None), (None, None), \n",
    "          (None, None), (None, None), (None, None),\n",
    "          (0, 1), \n",
    "          (None, None), (None, None), (None, None))\n",
    "#### BFGS and L-BFGS do not work without hacky fixes (returns RV array full of nans (ecc greater than 1))\n",
    "#### Nelder-Mead seems to work...\n",
    "best_fit_jitter = optimize.minimize(neg_log_likelihood, x0=np.array(fit_params), method='Nelder-Mead', \n",
    "                                    bounds=bounds, constraints=cons, options={'maxiter': 1000000000000, \n",
    "                                                                              'maxfev': 1000000000000, \n",
    "                                                                              # 'ftol': 1.e-7\n",
    "                                                                             }\n",
    "                                   )  # optimization\n",
    "# best fit parameters\n",
    "best = best_fit_jitter.x\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6df2737-d12f-4958-b414-617d77eddd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 119.591338196967$"
      ],
      "text/plain": [
       "119.59133819696733"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = get_sim_from_params(best, integrator='ias15', time_base=obs_time_base)\n",
    "inner = sim.particles[1]\n",
    "outer = sim.particles[2]\n",
    "# get values for e and beta\n",
    "e1_val, e2_val = inner.e, outer.e\n",
    "beta_1_val, beta_2_val = inner.m/(inner.m + outer.m), outer.m/(inner.m + outer.m)\n",
    "# substitute in all the values for ei and betai, as well as 2 * tau_e = tau_e1 = tau_e2 and tau_a = K * tau_e \n",
    "ddot_dis_eq_values = ddot_dis_eq.subs([(e1, e1_val), (e2, e2_val), (beta_1, beta_1_val), (beta_2, beta_2_val), (tau_e1, 2 * tau_e), (tau_e2, 2 * tau_e)]).subs(tau_alpha, K * tau_e)\n",
    "# solve\n",
    "K_val = sp.solve(ddot_dis_eq_values, K)[0]\n",
    "np.float64(K_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6a5f7-30d6-4dbf-b20f-471ae69f66b0",
   "metadata": {},
   "source": [
    "Convert $D$ to $K$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8b7f0d7-fc06-4f0f-8625-a2a8b328a3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_to_K(sample):\n",
    "    \"\"\"\n",
    "    Computes K = tau_a/tau_e for a set of parameters\n",
    "    \"\"\"\n",
    "    i, params = sample  # unpack\n",
    "    sim = get_sim_from_params(params, integrator='ias15', time_base=obs_time_base)\n",
    "    inner = sim.particles[1]\n",
    "    outer = sim.particles[2]\n",
    "    # get values for e and beta\n",
    "    e1_val, e2_val = inner.e, outer.e\n",
    "    beta_1_val, beta_2_val = inner.m/(inner.m + outer.m), outer.m/(inner.m + outer.m)\n",
    "    # get tau_e, tau_a, tau\n",
    "    ddot_dis_eq_values = ddot_dis_eq.subs([(e1, e1_val), (e2, e2_val), (beta_1, beta_1_val), (beta_2, beta_2_val), (tau_e1, 2 * tau_e), (tau_e2, 2 * tau_e)]).subs(tau_alpha, K * tau_e)\n",
    "    # solve\n",
    "    K_val = np.float64(sp.solve(ddot_dis_eq_values, K)[0])\n",
    "    return K_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ebb5d6-8a3a-4271-b271-c9363155b710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left( 2490000, \\  17\\right)$"
      ],
      "text/plain": [
       "(2490000, 17)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34f98025-799f-4973-971c-33a7895d7279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2490000/2490000 [44:33<00:00, 931.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# create parameter list to parallelize over\n",
    "par_list = [(i, sample) for i, sample in enumerate(flat_samples)]\n",
    "\n",
    "# parallelize it and process (takes about 90 minutes)\n",
    "with Pool() as pool_K_hist:\n",
    "    print('mapping...')\n",
    "    K_values = np.array(list(tqdm(pool_K_hist.imap(D_to_K, par_list), total=len(flat_samples)))).astype(np.float64)\n",
    "    print('done')\n",
    "\n",
    "# save!\n",
    "np.save('K_value_array_variable_01_paper_version', K_values)  # save the K values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
