{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d68f47c4-1bcd-41a9-af67-99424ec58c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ianchow/.local/lib/python3.10/site-packages/radvel/gp.py:32: ImportWarning: celerite not installed. GP kernals using celerite will not work. Try installing celerite using 'pip install celerite'\n",
      "  warnings.warn(\"celerite not installed. GP kernals using celerite will not work. \\\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import rebound as rb\n",
    "from matplotlib import pyplot as plt\n",
    "import celmech as cm\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "import radvel\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22386585-cdd1-40bd-8f27-9435079cabfb",
   "metadata": {},
   "source": [
    "Import the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28fa7a7-2af4-4f16-97a0-a6c607f0e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAY_1_2015 = 57143.5  # barycentric julian date for May 1, 2015 (the date of the HARPS instrument upgrade as per trifonov et al 2020)\n",
    "# 57143.5 is BJD for May 1, 2015\n",
    "# 57173.5 is BJD for May 31, 2015\n",
    "\n",
    "# harps\n",
    "hd_data_harps = pd.read_csv('hd45364_rvs.csv', sep = ';')\n",
    "# giant outlier at position 116 in the data (found manually earlier) which we remove\n",
    "hd_data_harps.drop(116, inplace=True)  # drop the row and keep the df in place\n",
    "# subtract 2.4e6 from all the rows in the data\n",
    "hd_data_harps.BJD -= 2.4e6\n",
    "# rename target to HARPS1 or HARPS2\n",
    "hd_data_harps['target'] = hd_data_harps.apply(lambda row: 'HARPS1' if row.BJD < MAY_1_2015 else 'HARPS2', axis = 1)\n",
    "# hires\n",
    "hd_data_hires = pd.read_csv('../hires_rvs.txt', sep = '\\t', index_col=False, header='infer', dtype=np.float64)\n",
    "hd_data_hires['BJD - 2,450,000'] += 50000.  # adding 50000 to have the same units as harps\n",
    "hd_data_hires['target'] = 'HIRES'\n",
    "hd_data_hires.columns = ['BJD', 'RV_mlc_nzp', 'e_RV_mlc_nzp', 'target']\n",
    "# concatenate two data sets one on top of the other\n",
    "hd_data = pd.concat((hd_data_harps, hd_data_hires), axis=0)  # matching BJD, RV_mlc_nzp and e_RV_mlc_nzp columns\n",
    "# reset index\n",
    "hd_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c75a2-a534-4fb1-81ca-40f602db0bc2",
   "metadata": {},
   "source": [
    "Functions to analytically compute the $K$ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33710501-044f-432e-961d-553c2bdb5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Very original parameters used in Hadden and Payne\n",
    "nbody_params =[ 2.27798546e+02,  7.25405874e+00,  5.39392010e+04,  1.71866112e-01, 1.17923823e-01,  \n",
    "               3.43881599e+02,  1.87692753e+01,  5.40138425e+04, 1.68408461e-01,  5.05903191e-02, \n",
    "               -3.28526403e-03, 0., 0., \n",
    "               1, \n",
    "               1.84, 0., 0.]  # inserted 0 for harps2 and hires for both rv offset and jitter\n",
    "\n",
    "# #Least squares fit: \n",
    "# fit_params = [ 2.28512793e+02, 7.27736501e+00, 5.39371914e+04, -4.66868256e-02, \n",
    "#                -1.78080009e-01, 3.43378038e+02, 1.78603341e+01, 5.40186750e+04, \n",
    "#                9.72945632e-02,  1.32194117e-01, -5.29072002e-01, 0., 0., 1, 2.428]#-7.68527759e-03] \n",
    "\n",
    "# Neg log likelihood jitter fit:\n",
    "\n",
    "fit_params = [2.27859008e+02, 7.20396587e+00,  5.39386707e+04, -7.17270858e-03, -2.13670237e-01,\n",
    "              3.44028221e+02, 1.82216479e+01,  5.47055869e+04, 1.14530821e-01,  3.81765820e-02,\n",
    "              -1.38087163e-01, -2.89290650e+00, 1.70788055e+00, \n",
    "              1.00000000e+00,\n",
    "              2.15025156e+00, 1.48605174e+00, 4.42809302e+00] \n",
    "\n",
    "STAR_MASS = 920  # 920 jupiter masses\n",
    "G = 2.825e-7  # converting G to jupiter masses, au, and days\n",
    "AUDAY_MS = 1.731e6  # conversion factor for au/day to m/s\n",
    "\n",
    "obs_time_base = np.median(hd_data_harps.BJD)\n",
    "\n",
    "def mass_to_semiamp(planet_mass, star_mass, period, eccentricity, inclination):\n",
    "    \"\"\"\n",
    "    planet mass (jupiter masses) to semi amplitude (in au/day)\n",
    "    \"\"\"\n",
    "    return ((2 * np.pi * G/period) ** (1/3) * (planet_mass * np.sin(inclination) / star_mass ** (2/3)) * (1/np.sqrt(1 - eccentricity ** 2)))\n",
    "\n",
    "\n",
    "def semiamp_to_mass(semiamp, star_mass, period, eccentricity, inclination):\n",
    "    \"\"\"\n",
    "    semi amplitude (in au/day) to planet mass (jupiter masses)\n",
    "    \"\"\"\n",
    "    return (((2 * np.pi * G/period) ** (-1/3)) * (semiamp / np.sin(inclination)) * np.sqrt(1 - eccentricity ** 2) * (star_mass ** (2/3)))\n",
    "\n",
    "\n",
    "def get_sim_from_params(params, integrator, time_base, star_mass = STAR_MASS, auday_ms = AUDAY_MS):\n",
    "    \"\"\"\n",
    "    takes in params array, returns a rebound Simulation object with those parameters\n",
    "    \n",
    "    param params: numpy array of params:\n",
    "    \n",
    "    for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i)\n",
    "    params[5 * num_planets + 4] is jitter for HARPS1\n",
    "    params[5 * num_planets + 5] is jitter for HARPS2\n",
    "    params[5 * num_planets + 6] is jitter for HIRES\n",
    "    \n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    param time_base: base time (to begin integration from) in the simulation\n",
    "    \"\"\"\n",
    "    \n",
    "    num_planets = 2 # 2 planets\n",
    "    \n",
    "    sim = rb.Simulation()\n",
    "    sim.integrator = integrator\n",
    "    sim.t = time_base  # keplerian and n-body models initialized at the same time offset\n",
    "    # print(sim.t)\n",
    "    if integrator == 'whfast':  # if using whfast integrator, set timestep\n",
    "        sim.dt = 1/50 * np.min([params[0], params[5]])  # timestep is 1/20th of the shortest orbital period of any planet\n",
    "        # print(sim.dt)\n",
    "    sim.units = ('AU', 'Mjupiter', 'day')\n",
    "    sim.add(m = star_mass)  # star mass as a constant\n",
    "    \n",
    "    inclination = np.arcsin(params[-4])  # sin(i) is fourth from the back of the array\n",
    "        \n",
    "    for i in range (0, num_planets):\n",
    "        # print(i)\n",
    "        # planet parameters\n",
    "        period = params[5*i]  # in days\n",
    "        semiamp = params[5*i + 1] / auday_ms # divide by auday_ms because semiamp given in m/s\n",
    "        eccentricity = params[5*i + 3] ** 2 + params[5*i + 4] ** 2  # eccentricity from secos, sesin\n",
    "        omega = np.arctan2(params[5*i + 4], params[5*i + 3])  # omega from arctan of sesin, secos  (in that order!)\n",
    "        # get tp by converting from tc\n",
    "        tp = radvel.orbit.timetrans_to_timeperi(tc = params[5*i + 2], per = period, ecc = eccentricity, omega = omega)\n",
    "        \n",
    "        # mass\n",
    "        mass = semiamp_to_mass(semiamp = semiamp, star_mass = star_mass, period = period, eccentricity = eccentricity, inclination = inclination)\n",
    "        \n",
    "        # adding to simulation\n",
    "        sim.add(m = mass, P = period, e = eccentricity, T = tp, omega = omega, inc = inclination)\n",
    "        \n",
    "    sim.move_to_com()  # move to center of mass\n",
    "    \n",
    "    return sim\n",
    "\n",
    "def get_simple_sim(masses, integrator = 'ias15', period_ratio = 3/2, epsilon=0.01):\n",
    "    \"\"\"\n",
    "    gets simple sim (for eccentricity track stuff)\n",
    "    param masses: array of planet masses\n",
    "    param integrator: integrator\n",
    "    param epsilon: amount by which the resonant period ratio should be offset from the equilibrium in the simulation\n",
    "    \"\"\"\n",
    "    sim = rb.Simulation()\n",
    "    sim.integrator = integrator\n",
    "    # central star\n",
    "    sim.add(m = 1)\n",
    "    \n",
    "    sim.add(m = masses[0], P = 1)\n",
    "    sim.add(m = masses[1], P = period_ratio * (1 + epsilon))\n",
    "\n",
    "    sim.move_to_com()\n",
    "    if integrator == 'whfast':\n",
    "        sim.dt = 1/50 * 1  # dy default use 1/50th of the inner planet's orbital period for the timestep if using whfast\n",
    "    return sim\n",
    "\n",
    "\n",
    "def get_rvs(params, instrument, times, integrator, time_base, auday_ms = AUDAY_MS):\n",
    "    \n",
    "    \"\"\"\n",
    "    Gets RVs from a Numpy array of planet params\n",
    "    \n",
    "    param params:     for i in range(0, num_planets):\n",
    "    \n",
    "    params[i + 0] is period\n",
    "    params[i + 1] is semiamp\n",
    "    params[i + 2] is tc (time of conjunction)\n",
    "    params[i + 3] is sqrt(e) * cos(omega)\n",
    "    params[i + 4] is sqrt(e) * sin(omega)\n",
    "    \n",
    "    params[5 * num_planets] is rv offset for HARPS1\n",
    "    params[5 * num_planets + 1] is rv offset for HARPS2\n",
    "    params[5 * num_planets + 2] is rv offset for HIRES\n",
    "    params[5 * num_planets + 3] is sin(i) (also params[-4])\n",
    "    params[5 * num_planets + 4] is jitter for HARPS1 (also params[-3])\n",
    "    params[5 * num_planets + 5] is jitter for HARPS2 (also params[-2])\n",
    "    params[5 * num_planets + 6] is jitter for HIRES (also params[-1])\n",
    "\n",
    "    param instrument: instrument (HARPS1, HARPS2, or HIRES)\n",
    "    param times: array of times to integrate over\n",
    "    param integrator: integrator to use, one of 'whfast' or 'ias15'\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sim = get_sim_from_params(params, integrator, time_base = time_base)\n",
    "    \n",
    "    sim_backwards = sim.copy()\n",
    "    sim_backwards.dt *= -1  # set timestep to be negative if integrating backwards\n",
    "\n",
    "    times = pd.Series(times)  # convert to series if not already\n",
    "    \n",
    "    forward_times = times[times - obs_time_base >= 0]\n",
    "    backward_times = times[times - obs_time_base < 0]\n",
    "    forward_indices = forward_times.index\n",
    "    backward_indices = backward_times.index\n",
    "    \n",
    "    # initialize rvs\n",
    "    rv_forward = np.zeros(len(forward_times))\n",
    "    rv_backward = np.zeros(len(backward_times))\n",
    "    \n",
    "    num_planets = 2  # find number of planets in params passed\n",
    "    \n",
    "    # get the rvs (z velocity, assuming 90 deg inclination) from the rebound simulation to compare with the actual simulation\n",
    "    for j, it in enumerate(zip(forward_indices, forward_times)):\n",
    "        i, t = it  # forward index, forward time\n",
    "        sim.integrate(t, exact_finish_time = 1)\n",
    "        # integrate to the specified time, exact_finish_time = 1 for ias15, \n",
    "        # sim.status()\n",
    "        star = sim.particles[0]\n",
    "        # print(instrument[i])\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_forward[j] = (-star.vz * auday_ms) + rv_offset  # use x-velocity of the star as the radial velocity, convert to m/s\n",
    "    \n",
    "    for j, it in enumerate(zip(backward_indices, backward_times)):\n",
    "        i, t = it  # backward index, backward time\n",
    "        sim_backwards.integrate(t, exact_finish_time = 1)\n",
    "        star = sim_backwards.particles[0]\n",
    "        # use one of 3 different radial velocity offsets depending on whether the data is from HARPS1, HARPS2 or HIRES\n",
    "        # print(instrument[i])\n",
    "        if instrument[i] == 'HARPS1':\n",
    "            rv_offset = params[5 * num_planets]\n",
    "        elif instrument[i] == 'HARPS2':\n",
    "            rv_offset = params[5 * num_planets + 1]\n",
    "        elif instrument[i] == 'HIRES':\n",
    "            rv_offset = params[5 * num_planets + 2]\n",
    "        else:\n",
    "            rv_offset = 0.\n",
    "        rv_backward[j] = (-star.vz * auday_ms) + rv_offset\n",
    "    \n",
    "    return np.concatenate((rv_backward, rv_forward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce918154-e93a-406c-a5e4-2062e9184c7e",
   "metadata": {},
   "source": [
    "Functions to compute the best-fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffdbe36b-50d4-4e0b-b6af-dbdcc4e37d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nbody_resids(params, integrator, data = hd_data):\n",
    "    \"\"\"\n",
    "    Gets the normalized residuals for the n-body fit with REBOUND\n",
    "    \"\"\"\n",
    "    obs_y = data.RV_mlc_nzp  # observed RVs\n",
    "    synth_y = get_rvs(params, data.target, data.BJD, integrator, time_base=obs_time_base)  # RVs from the rebound simulation\n",
    "    obs_yerr = data.e_RV_mlc_nzp  # y errors\n",
    "    return (obs_y - synth_y) / obs_yerr  # return normalized residuals\n",
    "\n",
    "\n",
    "def neg_log_likelihood(params, data = hd_data):\n",
    "    \"\"\"\n",
    "    Gets the negative log-likelihood (including a jitter term!) for use with scipy.optimize.minimze\n",
    "    \n",
    "    Iplements the log likelihood using the same method above\n",
    "    \n",
    "    \"\"\"\n",
    "    obs_y = data.RV_mlc_nzp  # observed RVs\n",
    "    \n",
    "    # inclination not handled sparately\n",
    "    # inclination = np.arcsin(params[-4])  # inclination is np.arcsin of the second to last parameter\n",
    "    \n",
    "    synth_y = get_rvs(params, data.target, data.BJD, 'ias15', time_base = obs_time_base)  # RVs from the rebound simulation\n",
    "    obs_yerr = data.e_RV_mlc_nzp  # y errors\n",
    "\n",
    "    conditions = [data.target == 'HARPS1', data.target == 'HARPS2', data.target == 'HIRES']  # conditions are harps1, harps2 or hires\n",
    "    jitters = params[-3:]  # jitters for HARPS1, HARPS2 and HIRES, in that order\n",
    "    \n",
    "    # get the jitter values for the corresponding data points\n",
    "    jitter = np.select(conditions, jitters, default=np.nan)\n",
    "\n",
    "    # compute the log-likelihood\n",
    "    log_likelihood = -1/2 * np.sum(((obs_y - synth_y) ** 2)/(obs_yerr ** 2 + jitter ** 2) \n",
    "                                   + np.log(np.sqrt(2 * np.pi * (obs_yerr ** 2 + jitter ** 2))))\n",
    "    \n",
    "    # log_likelihood = -1/2 * np.sum(np.log(variance) + ((obs_y - synth_y) ** 2/variance))\n",
    "    \n",
    "    return -log_likelihood  # negative since we are trying to minimize the negative log likelihood\n",
    "\n",
    "\n",
    "def get_tau_alphas(tau_alpha, m_inner, m_outer, period_ratio):\n",
    "    # use Kepler's third law to compute the ratio of semi-major axes in resonance from the period ratio in resonance\n",
    "    sma_ratio = period_ratio ** (2 / 3)  # ratio of outer planet's semi-major axis to inner\n",
    "    # define matrix A\n",
    "    A = np.array([[-1, 1],\n",
    "                  [m_outer, m_inner * sma_ratio]])\n",
    "    # compute gamma_1 and gamma_2\n",
    "    gammas = np.matmul(np.linalg.inv(A), np.array([-1 / tau_alpha, 0]))\n",
    "    # gamma = 1/tau\n",
    "    taus = 1 / gammas\n",
    "\n",
    "    return tuple(taus)  # returns (tau_alpha_outer, tau_alpha_inner) as a tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dae6f29-0fd5-4d0f-b8cd-2a4c21778438",
   "metadata": {},
   "source": [
    "Setting up the canonical transformations (we need `D_exprn`, `L2_exprn` and `fullflow` to compute $K$ values analytically):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "371a810b-2b21-47cc-b07d-c2e982bb4963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the cts\n",
    "gsim = get_sim_from_params(fit_params, integrator= 'ias15', time_base = obs_time_base)\n",
    "masses = np.array([gsim.particles[1].m, gsim.particles[2].m])/gsim.particles[0].m  # divide by star mass!\n",
    "sim = get_simple_sim(masses, integrator = 'ias15')\n",
    "pvars = cm.Poincare.from_Simulation(sim)\n",
    "pham = cm.PoincareHamiltonian(pvars)\n",
    "pham.add_MMR_terms(3, 1, max_order = 1, inclinations=False)  # try adding max order up to 3\n",
    "A = np.eye(pham.N_dof,dtype = int)\n",
    "A[0,:4] = [-2,3,1,0]\n",
    "A[1,:4] = [-2,3,0,1]\n",
    "A[2,:4] = [1,-1,0,0]\n",
    "A[3,:4] = [-2,3,0,0]\n",
    "angvars=sp.symbols(\"theta1,theta2,psi,l,phi1,phi2\",real=True)\n",
    "actions=sp.symbols(\"p1,p2,Psi,L,Phi1,Phi2\",positive=True)\n",
    "_,_,Psi,L,_,_=actions\n",
    "ct1 = cm.CanonicalTransformation.from_poincare_angles_matrix(pvars,A,new_qp_pairs=list(zip(angvars,actions)))\n",
    "ham1=ct1.old_to_new_hamiltonian(pham,do_reduction=True)\n",
    "ct2 = cm.CanonicalTransformation.polar_to_cartesian(ham1.full_qp_vars,indices=[0,1])\n",
    "ham2=ct2.old_to_new_hamiltonian(ham1)\n",
    "# ct_all here\n",
    "ct_all = cm.CanonicalTransformation.composite([ct1,ct2])\n",
    "oldvars = ct_all.old_qp_vars\n",
    "_,eta1,_,_,eta2,_,L1,kappa1,_,L2,kappa2,_= oldvars\n",
    "newvars = ct_all.new_qp_vars\n",
    "y1,y2,_,_,_,_,x1,x2,Psi,L,_,_ = newvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e832260c-edaf-47a9-9661-362deaf88817",
   "metadata": {},
   "outputs": [],
   "source": [
    "L_Psi_indices = np.array([ct_all.new_qp_vars.index(v) for v in [L, Psi]])\n",
    "xy_indices = np.array([ct_all.new_qp_vars.index(v) for v in [y1, y2, x1, x2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1d9ec94-dacd-4ea1-9d61-c5baa6dfd936",
   "metadata": {},
   "outputs": [],
   "source": [
    "D,L2res,rho = sp.symbols(\"D,L2,rho\")\n",
    "rho_val = (pham.particles[1].m/pham.particles[2].m) * (2/3)**(1/3)\n",
    "mtrx = sp.Matrix([[-1,1+rho],[0,3*rho + 2]])\n",
    "D_exprn,L2res_exprn = mtrx.inv() * sp.Matrix([L,Psi])\n",
    "Dval,L2val = [float(s.subs(ham2.full_qp).subs({rho:rho_val})) for s in (D_exprn,L2res_exprn)]\n",
    "newvars = [y1,y2,x1,x2,D_exprn]\n",
    "subsrule = dict(zip([L,Psi],mtrx * sp.Matrix([D,L2res])))\n",
    "\n",
    "tau_a1,tau_a2,tau_e1,tau_e2 = sp.symbols(\"tau_a1,tau_a2,tau_e1,tau_e2\")\n",
    "taus = [tau_a1,tau_a2,tau_e1,tau_e2]\n",
    "dyvars = [y1, y2, x1, x2, D]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd496473-7d2e-48cb-9d61-637f696dd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow matrices\n",
    "tau_a1,tau_a2,tau_e1,tau_e2 = sp.symbols(\"tau_a1,tau_a2,tau_e1,tau_e2\")\n",
    "disflow = sp.Matrix(np.zeros(pham.N_dim))\n",
    "for hk,tau in zip([(eta1,kappa1),(eta2,kappa2)],(tau_e1,tau_e2)):\n",
    "    h,k = hk\n",
    "    disflow[oldvars.index(h)] = -h/tau\n",
    "    disflow[oldvars.index(k)] = -k/tau\n",
    "disflow[oldvars.index(L1)] = -L1/tau_a1/sp.S(2)\n",
    "disflow[oldvars.index(L2)] = -L2/tau_a2/sp.S(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "485bce22-7650-46b2-be97-310a249d6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy.simplify.fu import TR10,TR10i,TR11\n",
    "mtrx_func = lambda i,j: sp.simplify(TR10i(TR10(sp.diff(ct_all.new_to_old(newvars[i]),oldvars[j]))))\n",
    "jac_old = sp.Matrix(len(newvars),len(oldvars),mtrx_func)\n",
    "newdisflow = sp.simplify(ct_all.old_to_new(jac_old * disflow))\n",
    "\n",
    "newdisflow = newdisflow.subs(subsrule)\n",
    "\n",
    "p1 = (x1*x1 + y1*y1)/sp.S(2)\n",
    "p2 = (x2*x2 + y2*y2)/sp.S(2)\n",
    "factor = rho * L2res / (3*rho+2)\n",
    "tau_alpha = 1/(1/tau_a1 - 1/tau_a2)\n",
    "Ddot_dis = -1*factor *(1/sp.S(2))* 1/tau_alpha - p1/tau_e1 - p2/tau_e2\n",
    "newdisflow_approx = sp.Matrix([(newdisflow[i] if i<4 else Ddot_dis) for i in range(5)])\n",
    "\n",
    "newflow = ham2.flow.subs(subsrule).subs(ham2.H_params)\n",
    "\n",
    "# full flow\n",
    "tau_alpha_sym, tau_e = sp.symbols('tau_alpha, tau_e')\n",
    "newpars = {L2res:L2val,rho:rho_val}\n",
    "newflow_N = newflow.subs(newpars)\n",
    "newdisflow_approx_N = newdisflow_approx.subs(newpars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83ae725a-3071-4e2d-bab8-dfa229278520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "from scipy.linalg import solve as lin_solve\n",
    "def newton_solve(fun,Dfun,guess,max_iter=100,rtol=1e-6,atol=1e-12):\n",
    "    y = guess.copy()\n",
    "    for itr in range(max_iter):\n",
    "        f = fun(y)\n",
    "        Df = Dfun(y)\n",
    "        dy = -1 * lin_solve(Df,f)\n",
    "        y+=dy\n",
    "        if np.alltrue( np.abs(dy) < rtol * np.abs(y) + atol ):\n",
    "            break\n",
    "    else:\n",
    "        warnings.warn(\"did not converge\")\n",
    "    return y\n",
    "\n",
    "# full flow\n",
    "fullflow = sp.Matrix(list(newflow_N) + [0]) + newdisflow_approx_N\n",
    "taus = [tau_a1,tau_a2,tau_e1,tau_e2]\n",
    "dyvars = [y1, y2, x1, x2, D]\n",
    "flow_fn=sp.lambdify(dyvars+taus,fullflow)\n",
    "jac_fn=sp.lambdify(\n",
    "    dyvars+taus,\n",
    "    sp.Matrix(5,5,lambda i,j : sp.diff(fullflow[i],dyvars[j]) )\n",
    ")\n",
    "# negative so it works properly\n",
    "tauvals = list(get_tau_alphas(-50 * 1e3, masses[0], masses[1], period_ratio=3/2)) + [1e3, 1e3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31fd01da-724d-488b-87e0-eda4fc23281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "times = np.linspace(0,6e3,200)\n",
    "f=lambda t,x: flow_fn(*x,*tauvals).reshape(-1)\n",
    "Df = lambda t,x: jac_fn(*x,*tauvals)\n",
    "soln=solve_ivp(f,(times[0],times[-1]),[0,0,0,0,float(Dval)],method='Radau',t_eval=times,jac=Df)\n",
    "\n",
    "f=lambda x: flow_fn(*x,*tauvals).reshape(-1)\n",
    "Df = lambda x: jac_fn(*x,*tauvals)\n",
    "root=newton_solve(f,Df,soln.y.T[-1])\n",
    "\n",
    "xydict = dict(zip(dyvars, root))\n",
    "# sub with the equilibrium values of d, y1, y2, x1, x2, set ddot = 0 and set tau a1 equal to tau a2\n",
    "fullflow_N = fullflow.subs(xydict).subs([(-tau_e2, tau_e), (-tau_e1, tau_e)])[4]\n",
    "\n",
    "# substitute 1/tau_a = 1/tau_a1 - 1/tau_a2 usign the coefficient\n",
    "\n",
    "ddot_eq = fullflow_N.subs(-fullflow_N.coeff(1/tau_a2)/tau_alpha, -fullflow_N.coeff(1/tau_a2)/tau_alpha_sym)\n",
    "sp.solve(ddot_eq, tau_alpha_sym)\n",
    "\n",
    "Ddot_dis = -1*factor *(1/sp.S(2))* 1/tau_alpha - p1/tau_e1 - p2/tau_e2\n",
    "newdisflow_approx = sp.Matrix([(newdisflow[i] if i<4 else Ddot_dis) for i in range(5)])\n",
    "fullflow = sp.Matrix(list(newflow) + [0]) + newdisflow_approx# .subs(newpars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a29c6d9-4505-4ac3-a98f-224e606b7ebf",
   "metadata": {},
   "source": [
    "Function computing $K$ from $D$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63b4525d-f398-42e8-a287-1c28cfa1cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# D to K\n",
    "\n",
    "def D_to_K(flow_mat, root, dyvars=dyvars):\n",
    "    \"\"\"\n",
    "    Computes K = tau_a/tau_e using the flow matrix and its roots\n",
    "\n",
    "    Flow matrix is in the form zdot = d/dt[y1, y2, x1, x2, D] and settting D_dot to 0\n",
    "    Root is vector in the from z = [y1, y2, x1, x2, D]\n",
    "\n",
    "    Flow matrix should have free symbols for tau_a1, tau_a2, tau_e1, tau_e2, x1, x2, y1, y2, D\n",
    "    (rho and L2 values should be replaced before passing to the function)\n",
    "    \"\"\"\n",
    "    tau_alpha_sym, tau_e, K = sp.symbols('tau_alpha, tau_e, K')\n",
    "    # sub with equilibrium values of y1, y2, x1, x2, d, and set tau_e1 = tau_e2 = tau_e\n",
    "    xydict = dict(zip(dyvars, root))\n",
    "    # tau_e1, tau_e2, tau_a1, tau_a2 need to be defined\n",
    "    flow_mat_N = flow_mat.subs(xydict).subs([(-tau_e2, tau_e), (-tau_e1, tau_e)])[\n",
    "        -1]  # D entry is at the end of the matrix\n",
    "    # substitute tau_a1 = 1/(1/tau_a + 1/tau_a2) and them sub in tau_a = K * tau_e into the sympy expression\n",
    "    ddot_eq = flow_mat_N.subs(tau_a1, 1 / (1 / tau_alpha_sym + 1 / tau_a2)).subs(tau_alpha_sym, K * tau_e)\n",
    "    # return solving for tau_a in terms of tau_e (coefficient is equal to K)\n",
    "    return sp.solve(ddot_eq, K)[0]  # since sp.solve returns a singleton list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739c447b-fd9e-43fb-9286-edea1ba04a25",
   "metadata": {},
   "source": [
    "Perform the fitting procedure to find the best-fit parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9670850a-1fab-435c-813a-79ade11cd032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.27859014e+02,  7.20396610e+00,  5.39386707e+04, -7.17559020e-03,\n",
       "       -2.13669346e-01,  3.44028217e+02,  1.82216589e+01,  5.47055869e+04,\n",
       "        1.14531498e-01,  3.81775332e-02, -1.38093056e-01, -2.89290989e+00,\n",
       "        1.70793414e+00,  1.00000000e+00,  2.15024775e+00,  1.48604155e+00,\n",
       "        4.42811849e+00])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounds of (0, 1) for sin(i), everything else can vary however\n",
    "bounds = ((None, None), (None, None), (None, None), (None, None), (None, None), \n",
    "          (None, None), (None, None), (None, None), (None, None), (None, None), \n",
    "          (None, None), (None, None), (None, None),\n",
    "          (0, 1), \n",
    "          (None, None), (None, None), (None, None))\n",
    "\n",
    "best_fit_jitter = optimize.minimize(neg_log_likelihood, x0=np.array(fit_params), method='Nelder-Mead', \n",
    "                                    bounds=bounds, options={'maxiter': np.inf, 'maxfev': np.inf})  # optimization\n",
    "# best fit parameters\n",
    "best = best_fit_jitter.x\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c73376-b810-46b0-ae63-7318cf4885e2",
   "metadata": {},
   "source": [
    "Analytically compute $K$ for the best-fit parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "296b0038-6028-4f57-bdd2-fbfb075bb709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rebound simulation from sample\n",
    "samp_sim = get_sim_from_params(best, integrator='ias15', time_base=obs_time_base)\n",
    "# masses of inner and outer planets\n",
    "inner_mass = samp_sim.particles[1].m\n",
    "outer_mass = samp_sim.particles[2].m\n",
    "# convert rebound simulation to pvars\n",
    "samp_pvars = cm.Poincare.from_Simulation(samp_sim)\n",
    "# compute rho value using the equation above:\n",
    "samp_rho_val = (inner_mass / outer_mass) * ((2 / 3) ** (1 / 3))\n",
    "# get the L and Psi values, as well as x and y values, by transforming from samp_pvars (eta, kappa) -> (y, x)\n",
    "samp_L_Psi_vals = ct_all.old_to_new_array(samp_pvars.values)[L_Psi_indices]  # values of L and Psi in that order\n",
    "samp_xy_vals = ct_all.old_to_new_array(samp_pvars.values)[xy_indices]  # values y1, y2, x1, x2 in that order\n",
    "# get D and L2 values using L and Psi, as well as the rho value computed earlier, from the D_exprn expression\n",
    "samp_D_val = D_exprn.subs(zip([L, Psi], samp_L_Psi_vals)).subs(rho,\n",
    "                                                               samp_rho_val)  # use L and Psi to compute the D value\n",
    "samp_L2_val = L2res_exprn.subs(zip([L, Psi], samp_L_Psi_vals)).subs(rho,\n",
    "                                                                    samp_rho_val)  # also use L and Psi to compute L2 value\n",
    "# parameterize root as [y1, y2, x1, x2, D]\n",
    "samp_root = np.append(samp_xy_vals, samp_D_val)\n",
    "# compute rho, L2 for this sample for substituting into fullflow\n",
    "samp_rho_L2_pars = dict(zip([rho, L2res], [samp_rho_val, samp_L2_val]))\n",
    "# finally, convert from D to K using the D_to_K function:\n",
    "D_value = samp_D_val  # record sample D value as well as K value from D\n",
    "# make sure to substitute in rho and L2 for this specific(!) sample into the D to K values\n",
    "K_value = D_to_K(fullflow.subs(samp_rho_L2_pars),\n",
    "                     samp_root)  # use the fullflow function from earlier since that doesn't change (two planets and only considering 1st order terms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98c63a46-b163-4d53-ad10-990962d2070a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle 122.257855876586$"
      ],
      "text/plain": [
       "122.257855876586"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K_value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
